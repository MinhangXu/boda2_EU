{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "considerable-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "import shutil\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (random_split, DataLoader, TensorDataset, ConcatDataset)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "from Bio import motifs\n",
    "\n",
    "import boda\n",
    "from boda.generator.parameters import StraightThroughParameters\n",
    "from boda.generator import FastSeqProp\n",
    "from boda.generator.plot_tools import matrix_to_dms, ppm_to_IC, ppm_to_pwm\n",
    "from boda.model.mpra_basset import MPRA_Basset\n",
    "from boda.common import constants, utils\n",
    "\n",
    "boda_src = os.path.join( os.path.dirname( os.path.dirname( os.getcwd() ) ), 'src' )\n",
    "sys.path.insert(0, boda_src)\n",
    "\n",
    "from main import unpack_artifact, model_fn\n",
    "from pymeme import streme, parse_streme_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "close-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for variable-length sequences\n",
    "def get_onehots(in_df, seq_column='nt_sequence', extra_str=''):\n",
    "    padding_fn = partial(utils.row_pad_sequence,\n",
    "                            in_column_name=seq_column,\n",
    "                            padded_seq_len=600)    \n",
    "    print('Padding sequences' + extra_str)\n",
    "    sequence_list = list(in_df.progress_apply(padding_fn, axis=1))     \n",
    "    print('Tokenizing sequences' + extra_str)\n",
    "    onehot_sequences = torch.stack([utils.dna2tensor(subsequence) for subsequence in tqdm(sequence_list)])\n",
    "    return onehot_sequences\n",
    "\n",
    "def get_predictions(onehot_sequences, model, eval_batch_size = 128, num_workers=2, extra_str=''):\n",
    "    temp_dataset = TensorDataset(onehot_sequences)\n",
    "    temp_dataloader = DataLoader(temp_dataset, batch_size=eval_batch_size, shuffle=False, num_workers=num_workers)\n",
    "    print('Getting predictions' + extra_str)  \n",
    "    preds = []\n",
    "    for local_batch in tqdm(temp_dataloader):\n",
    "        preds.append(model(local_batch[0].cuda()).cpu().detach().numpy())       \n",
    "    preds_array = np.concatenate(preds, axis=0)  \n",
    "    return preds_array\n",
    "\n",
    "def append_predictions(dfs, model_paths, model_nicknames=None):\n",
    "    activity_columns = ['K562_mean', 'HepG2_mean', 'SKNSH_mean']\n",
    "    print('------------- Getting input tensors for each df -------------')\n",
    "    print('')\n",
    "    onehot_inputs = [get_onehots(df) for df in dfs]    \n",
    "    if model_nicknames is None:\n",
    "        model_nicknames = [str(i) for i in range(1, len(model_paths)+1)]\n",
    "    assert len(model_nicknames) == len(model_paths)\n",
    "    if os.path.isdir('./artifacts'):\n",
    "        shutil.rmtree('./artifacts')\n",
    "    prediction_columns_dict = {}\n",
    "    for model_idx, model_path in enumerate(model_paths):\n",
    "        unpack_artifact(model_path)\n",
    "        model_dir = './artifacts'\n",
    "        model = model_fn(model_dir)\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "        model_nickname = model_nicknames[model_idx]\n",
    "        prediction_columns = [activity_name.rstrip('mean') + 'pred_' \\\n",
    "                              + model_nickname for activity_name in activity_columns]\n",
    "        prediction_columns_dict[model_nickname] = prediction_columns\n",
    "        print('')\n",
    "        print(f'------------- Getting model_{model_nickname} predictions for each df -------------')\n",
    "        print('')\n",
    "        for df_idx, df in enumerate(dfs):\n",
    "            df[prediction_columns] = get_predictions(onehot_inputs[df_idx], model)\n",
    "    return prediction_columns_dict\n",
    "\n",
    "def single_scatterplot(data_df, x_axis, y_axis, color_axis, fig_size=(15,8), dot_size=0.5, title='',\n",
    "                       dot_alpha=0.5, style='seaborn-whitegrid', colormap='winter',\n",
    "                       x_label='True', y_label='Predicted', color_label='l2fc SE', title_font_size=18,\n",
    "                       title_font_weight='medium', axis_font_size=16):\n",
    "    with plt.style.context(style):\n",
    "        fig, ax = plt.subplots()    \n",
    "        data_df.plot(kind='scatter', x=x_axis, y=y_axis, figsize=fig_size, c=color_axis, ax=ax,\n",
    "                        alpha=dot_alpha, s=dot_size, colormap=colormap)\n",
    "        plt.xlabel(x_label, fontsize=axis_font_size)\n",
    "        plt.ylabel(y_label, fontsize=axis_font_size)\n",
    "\n",
    "        f = plt.gcf()\n",
    "        cax = f.get_axes()[1]\n",
    "        cax.set_ylabel(color_label, fontsize=axis_font_size)\n",
    "\n",
    "        x_min, y_min = data_df[[x_axis, y_axis]].min().to_numpy() \n",
    "        x_max, y_max = data_df[[x_axis, y_axis]].max().to_numpy()\n",
    "        min_point, max_point = max(x_min, y_min), min(x_max, y_max)\n",
    "        plt.plot((min_point,max_point), (min_point,max_point), color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "        Pearson = round(data_df[[x_axis, y_axis]].corr(method='pearson')[x_axis][1], 2)\n",
    "        Spearman = round(data_df[[x_axis, y_axis]].corr(method='spearman')[x_axis][1], 2)\n",
    "\n",
    "        title = f'{title}  |  Pearson={Pearson}  Spearman={Spearman}'\n",
    "        ax.set_title(title, fontdict={'fontsize': title_font_size, 'fontweight': title_font_weight}, pad=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "specialized-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtex_df = pd.read_csv('gs://syrgoth/data/MPRA_GTEX.txt', sep=\" \", low_memory=False)\n",
    "# gtex_noShrink_df = pd.read_csv('gs://syrgoth/data/MPRA_GTEX_cellDisp_noShrink.txt', sep=\" \", low_memory=False)\n",
    "# gtex_Shrink_df = pd.read_csv('gs://syrgoth/data/MPRA_GTEX_cellDisp_Shrink.txt', sep=\" \", low_memory=False)\n",
    "\n",
    "all_boda_df = pd.read_csv('gs://syrgoth/data/MPRA_ALL_no_cutoffs.txt', sep=\" \", low_memory=False)\n",
    "all_boda_df.at[345812, 'nt_sequence'] = 'TGTAGAAAAAAATATATATATATATGAACAACGCATAATCCTGGAAATATAAGGAAAAATTAAATTTTCTCCTCTGGGAAAAATTTATACAGTAATGATTCTTGCTCTTTAATTTTTGTTTGAAAGAAATCTAGACATTTAAAAAACCCCAGTGGTAGAATTGTCTTGTTAAAAAGGGACATCAAGTAAAAGGCCAGGGG'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fluid-murray",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Getting input tensors for each df -------------\n",
      "\n",
      "Padding sequences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01e592bc83a47aba5b891826b7672d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/813051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sequences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd3f640b4af4bcc90d0f49db1d76f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/813051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20211113_021200 in eval mode\n",
      "\n",
      "------------- Getting model_relu predictions for each df -------------\n",
      "\n",
      "Getting predictions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdb61f8de964f95a45b19267a22f634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20211110_194934 in eval mode\n",
      "\n",
      "------------- Getting model_relu6 predictions for each df -------------\n",
      "\n",
      "Getting predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "archive unpacked in ./\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52efd6437e1d458081efa231614a312d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20211119_011437 in eval mode\n",
      "\n",
      "------------- Getting model_relu_HD predictions for each df -------------\n",
      "\n",
      "Getting predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "archive unpacked in ./\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb5c3d72f9e4f4b8fd2aa25cab65027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_nicknames = ['relu', 'relu6', 'relu_HD']\n",
    "model_paths = ['gs://syrgoth/aip_ui_test/model_artifacts__20211113_021200__287348.tar.gz',\n",
    "               'gs://syrgoth/aip_ui_test/model_artifacts__20211110_194934__672830.tar.gz',\n",
    "               'gs://syrgoth/aip_ui_test/model_artifacts__20211119_011437__338420.tar.gz']\n",
    "\n",
    "# performance_dfs = [gtex_df, gtex_noShrink_df, gtex_Shrink_df]\n",
    "performance_dfs = [all_boda_df]\n",
    "\n",
    "prediction_columns_dict = append_predictions(performance_dfs, model_paths, model_nicknames=model_nicknames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beneficial-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prediction_columns = ['K562_pred_aggreg', 'HepG2_pred_aggreg', 'SKNSH_pred_aggreg']\n",
    "for i in range(len(avg_prediction_columns)):\n",
    "    for df in performance_dfs:\n",
    "        df[avg_prediction_columns[i]] = df[[columns[i] for columns in prediction_columns_dict.values()]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_drop_list = [column for sublist in prediction_columns_dict.values() for column in sublist]\n",
    "\n",
    "# for df in performance_dfs:\n",
    "#     df.drop(column_drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "assumed-punishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relu': ['K562_pred_relu', 'HepG2_pred_relu', 'SKNSH_pred_relu'],\n",
       " 'relu6': ['K562_pred_relu6', 'HepG2_pred_relu6', 'SKNSH_pred_relu6'],\n",
       " 'relu_HD': ['K562_pred_relu_HD', 'HepG2_pred_relu_HD', 'SKNSH_pred_relu_HD']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_columns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "moderate-landscape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HepG2_mean', 'HepG2_std', 'ID_count', 'IDs', 'K562_mean', 'K562_std',\n",
       "       'OL', 'OL_count', 'SKNSH_mean', 'SKNSH_std', 'chr', 'class',\n",
       "       'ctrl_mean_hepg2', 'ctrl_mean_k562', 'ctrl_mean_sknsh', 'data_project',\n",
       "       'exp_mean_hepg2', 'exp_mean_k562', 'exp_mean_sknsh', 'lfcSE_hepg2',\n",
       "       'lfcSE_k562', 'lfcSE_sknsh', 'nt_sequence', 'K562_pred_relu',\n",
       "       'HepG2_pred_relu', 'SKNSH_pred_relu', 'K562_pred_relu6',\n",
       "       'HepG2_pred_relu6', 'SKNSH_pred_relu6', 'K562_pred_relu_HD',\n",
       "       'HepG2_pred_relu_HD', 'SKNSH_pred_relu_HD', 'K562_pred_aggreg',\n",
       "       'HepG2_pred_aggreg', 'SKNSH_pred_aggreg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.set_option('display.max_columns', None)\n",
    "\n",
    "all_boda_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "focused-moldova",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835a8ee0495944b8a52f56518517c5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#file_names = ['MPRA_GTEX_pred.txt', 'MPRA_GTEX_cellDisp_noShrink_pred.txt', 'MPRA_GTEX_cellDisp_Shrink_pred.txt']\n",
    "file_names = ['MPRA_ALL_no_cutoffs_pred.txt']\n",
    "\n",
    "#performance_dfs = [gtex_df, gtex_noShrink_df, gtex_Shrink_df]\n",
    "for name_idx, df in tqdm(enumerate(performance_dfs)):\n",
    "    df.to_csv(file_names[name_idx], index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-karen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
