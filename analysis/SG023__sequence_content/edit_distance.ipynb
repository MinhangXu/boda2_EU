{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a143d8d4-ebda-424c-b262-f83dd639fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "import csv\n",
    "import multiprocessing\n",
    "\n",
    "import tqdm.notebook as tqnb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import boda\n",
    "from boda.common.utils import KmerFilter, dna2tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e5ae470-a8ff-4985-9f1f-f80842e1ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor_200(in_tensor):\n",
    "    out_tensor = torch.cat([\n",
    "        in_tensor,\n",
    "        torch.zeros((4,200-in_tensor.shape[1]), device=in_tensor.device)\n",
    "    ], dim=1)\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70ee8bf-a8d0-4da3-9958-dea25a1d36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_table = pd.read_table('boda_round_1_controls_20211215.seq', sep='\\t', header=None, names=['ID','sequence'])\n",
    "\n",
    "seq_tensor = torch.stack(\n",
    "    [ pad_tensor_200(dna2tensor(line['sequence'])) for i, line in seq_table.iterrows() ], \n",
    "    dim=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59667236-2f6e-41c6-a040-ce442b965af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tensor = seq_tensor.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfea3186-aec9-4579-b2a9-d531bbbd6839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f838bf9a37c4e168c11fadb70949ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "section_size = torch.arange(token_tensor.shape[0]).flip(dims=[0])\n",
    "flat_idxer   = torch.cat([torch.tensor([0],dtype=torch.long),torch.cumsum(section_size,dim=0,dtype=torch.long)])\n",
    "\n",
    "edit_dist = torch.full((torch.arange(token_tensor.shape[0]).sum(),), fill_value=np.nan)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqnb.tqdm(range(token_tensor.shape[0]-1)):\n",
    "        edit_dist[flat_idxer[i]:flat_idxer[i+1]] = (token_tensor[i][None,:] != token_tensor[i+1:]).sum(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961f5b08-f724-4bef-bf67-a99cb780543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'condensed_distance': edit_dist}, 'hamming__condensed_distance_matrix.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8d373-3b45-465b-a52c-631ad3980ada",
   "metadata": {
    "tags": []
   },
   "source": [
    "## redo shuffled\n",
    "\n",
    "rerun this with a fresh kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0010bb97-b0ce-48fa-83d3-2460e4c4ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "import csv\n",
    "import multiprocessing\n",
    "\n",
    "import tqdm.notebook as tqnb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import boda\n",
    "from boda.common.utils import KmerFilter, dna2tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46b65a5-a141-463c-9d7a-0ddfe852b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor_200(in_tensor):\n",
    "    out_tensor = torch.cat([\n",
    "        in_tensor,\n",
    "        torch.zeros((4,200-in_tensor.shape[1]), device=in_tensor.device)\n",
    "    ], dim=1)\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9795348-b1c2-471c-942a-4771185408b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_table = {'ID': [], 'sequence': []}\n",
    "\n",
    "with open('boda_round_1_controls_20211215.shuffle_1.fa', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i % 2 == 0:\n",
    "            seq_table['ID'].append( line.rstrip().lstrip('>') )\n",
    "        else:\n",
    "            seq_table['sequence'].append( line.rstrip() )\n",
    "            \n",
    "seq_table = pd.DataFrame.from_dict(seq_table, orient='columns')\n",
    "\n",
    "seq_tensor = torch.stack(\n",
    "    [ pad_tensor_200(dna2tensor(line['sequence'])) for i, line in seq_table.iterrows() ], \n",
    "    dim=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4811bdf-c5f5-4f02-ad5c-3da6402b318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tensor = seq_tensor.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc4595f-9ab2-4f99-b188-95196897f824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f9c6af7907442e8ac988d1de0574ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "section_size = torch.arange(token_tensor.shape[0]).flip(dims=[0])\n",
    "flat_idxer   = torch.cat([torch.tensor([0],dtype=torch.long),torch.cumsum(section_size,dim=0,dtype=torch.long)])\n",
    "\n",
    "edit_dist = torch.full((torch.arange(token_tensor.shape[0]).sum(),), fill_value=np.nan)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqnb.tqdm(range(token_tensor.shape[0]-1)):\n",
    "        edit_dist[flat_idxer[i]:flat_idxer[i+1]] = (token_tensor[i][None,:] != token_tensor[i+1:]).sum(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d57d92b-e07a-4360-8615-bef5377ba729",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'condensed_distance': edit_dist}, 'hamming__condensed_distance_matrix.shuffle_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15856ecf-6e10-4974-9b96-737b45f572d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
