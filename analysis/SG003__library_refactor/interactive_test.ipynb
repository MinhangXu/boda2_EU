{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-1.3.1-py3-none-any.whl (805 kB)\n",
      "\u001b[K     |████████████████████████████████| 805 kB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML<=5.4.1,>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.19.2)\n",
      "Collecting pyDeprecate==0.3.0\n",
      "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.7.1)\n",
      "Collecting fsspec[http]>=2021.4.0\n",
      "  Downloading fsspec-2021.4.0-py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 15.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (0.18.2)\n",
      "Collecting tensorboard!=2.5.0,>=2.2.0\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (20.8)\n",
      "Collecting torchmetrics>=0.2.0\n",
      "  Downloading torchmetrics-0.3.2-py3-none-any.whl (274 kB)\n",
      "\u001b[K     |████████████████████████████████| 274 kB 85.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (4.55.1)\n",
      "Requirement already satisfied, skipping upgrade: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->pytorch_lightning) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: requests; extra == \"http\" in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>=2021.4.0->pytorch_lightning) (2.25.1)\n",
      "Requirement already satisfied, skipping upgrade: aiohttp; extra == \"http\" in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>=2021.4.0->pytorch_lightning) (3.7.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.12.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.34.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.36.2)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (49.6.0.post20201009)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.24.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytorch_lightning) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (1.26.2)\n",
      "Requirement already satisfied, skipping upgrade: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (5.1.0)\n",
      "Requirement already satisfied, skipping upgrade: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (20.3.0)\n",
      "Requirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.8)\n",
      "Installing collected packages: pyDeprecate, fsspec, tensorboard, torchmetrics, pytorch-lightning\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.8.5\n",
      "    Uninstalling fsspec-0.8.5:\n",
      "      Successfully uninstalled fsspec-0.8.5\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.0.0\n",
      "    Uninstalling pytorch-lightning-1.0.0:\n",
      "      Successfully uninstalled pytorch-lightning-1.0.0\n",
      "Successfully installed fsspec-2021.4.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.1 tensorboard-2.4.1 torchmetrics-0.3.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch_lightning --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import shutil\n",
    "import argparse\n",
    "import tarfile\n",
    "import random\n",
    "import tempfile\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as ptl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "import boda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n",
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(ptl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    data_module = getattr(boda.data, args['Main args'].data_module)\n",
    "    model_module= getattr(boda.model, args['Main args'].model_module)\n",
    "    graph_module= getattr(boda.graph, args['Main args'].graph_module)\n",
    "\n",
    "    data = data_module(**vars(data_module.process_args(args)))\n",
    "    model= model_module(**vars(model_module.process_args(args)))\n",
    "\n",
    "    model.__class__ = type(\n",
    "        'BODA_module',\n",
    "        (model_module,graph_module),\n",
    "        vars(graph_module.process_args(args))\n",
    "    )\n",
    "\n",
    "    os.makedirs('/tmp/output/artifacts', exist_ok=True)\n",
    "    trainer = Trainer.from_argparse_args(args['pl.Trainer'])\n",
    "    \n",
    "    trainer.fit(model, data)\n",
    "    \n",
    "    _save_model(data_module, model_module, graph_module, \n",
    "                model, trainer, args['Main args'])\n",
    "    \n",
    "    return data_module, model_module, graph_module, model, trainer, args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_model(data_module, model_module, graph_module, \n",
    "                model, trainer, main_args):\n",
    "    local_dir = '/tmp/output/artifacts'\n",
    "    save_dict = {\n",
    "        'data_module'  : data_module.__name__,\n",
    "        'data_hparams' : data_module.process_args(args),\n",
    "        'model_module' : model_module.__name__,\n",
    "        'model_hparams': model_module.process_args(args),\n",
    "        'graph_module' : graph_module.__name__,\n",
    "        'graph_hparams': graph_module.process_args(args),\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'timestamp'    : time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    }\n",
    "    torch.save(save_dict, os.path.join(local_dir,'torch_checkpoint.pt'))\n",
    "    \n",
    "    rtag = random.randint(1000,9999)\n",
    "    filename=f'model_artifacts__{save_dict[\"timestamp\"]}__{rtag}.tar.gz'\n",
    "    with tarfile.open(os.path.join('/tmp/output/',filename), 'w:gz') as tar:\n",
    "        tar.add(local_dir,arcname='artifacts')\n",
    "    \n",
    "    if 'gs://' in main_args.artifact_path:\n",
    "        subprocess.check_call(\n",
    "            ['gsutil', 'cp', os.path.join('/tmp/output/',filename), main_args.artifact_path]\n",
    "        )\n",
    "    else:\n",
    "        os.makedirs(main_args.artifact_path, exist_ok=True)\n",
    "        shutil.copy(os.path.join('/tmp/output/',filename), main_args.artifact_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_model(data_module, model_module, graph_module, \n",
    "                model, trainer, args):\n",
    "    local_dir = args['pl.Trainer'].default_root_dir\n",
    "    save_dict = {\n",
    "        'data_module'  : data_module.__name__,\n",
    "        'data_hparams' : data_module.process_args(args),\n",
    "        'model_module' : model_module.__name__,\n",
    "        'model_hparams': model_module.process_args(args),\n",
    "        'graph_module' : graph_module.__name__,\n",
    "        'graph_hparams': graph_module.process_args(args),\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'timestamp'    : time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    }\n",
    "    torch.save(save_dict, os.path.join(local_dir,'torch_checkpoint.pt'))\n",
    "    \n",
    "    rtag = random.randint(1000,9999)\n",
    "    filename=f'model_artifacts__{save_dict[\"timestamp\"]}__{rtag}.tar.gz'\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        with tarfile.open(os.path.join(tmpdirname,filename), 'w:gz') as tar:\n",
    "            tar.add(local_dir,arcname='artifacts')\n",
    "\n",
    "        if 'gs://' in args['Main args'].artifact_path:\n",
    "            subprocess.check_call(\n",
    "                ['gsutil', 'cp', os.path.join(tmpdirname,filename), args['Main args'].artifact_path]\n",
    "            )\n",
    "        else:\n",
    "            os.makedirs(args['Main args'].artifact_path, exist_ok=True)\n",
    "            shutil.copy(os.path.join(tmpdirname,filename), args['Main args'].artifact_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(model_dir):\n",
    "    checkpoint = torch.load(os.path.join(model_dir,'torch_checkpoint.pt'))\n",
    "    model_module = getattr(boda, checkpoint['model_module'])\n",
    "    model        = model_module(**checkpoint['model_hparams'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f'Loaded model from {checkpoint[\"timestamp\"]}')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process runtime arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command line args to use for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python /home/ubuntu/boda2/src/main.py --data_module BODA2_DataModule --dataFile_path  ../../data/BODA.MPRA.txt --ValSize_pct  5 --TestSize_pct  5 --batchSize  32 --paddedSeqLen 600 --numWorkers 1 --model_module Basset --n_outputs  3 --loss_criterion MSELoss --graph_module CNNBasicTraining --gpus 1 --min_epochs 5 --max_epochs 5 --default_root_dir /tmp/output/artifacts --artifact_path /opt/ml/output '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd_str = '--data_module BODA2_DataModule ' +\\\n",
    "            '--dataFile_path  ../../data/BODA.MPRA.txt ' +\\\n",
    "            '--ValSize_pct  5 --TestSize_pct  5 ' +\\\n",
    "            '--batchSize  32 --paddedSeqLen 600 --numWorkers 1 ' +\\\n",
    "          '--model_module Basset ' +\\\n",
    "            '--n_outputs  3 --loss_criterion MSELoss ' +\\\n",
    "          '--graph_module CNNBasicTraining ' +\\\n",
    "          '--gpus 1 --min_epochs 5 --max_epochs 5 --default_root_dir /tmp/output/artifacts ' +\\\n",
    "          '--artifact_path /opt/ml/output '\n",
    "\n",
    "'python /home/ubuntu/boda2/src/main.py ' + cmd_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set base args for script\n",
    "\n",
    "Basic arguments to identify which submodules are used and where data will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--pretrained_weights'], dest='pretrained_weights', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Pretrained weights.', metavar=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"BODA trainer\", add_help=False)\n",
    "group = parser.add_argument_group('Main args')\n",
    "group.add_argument('--data_module', type=str, required=True, help='BODA data module to process dataset.')\n",
    "group.add_argument('--model_module',type=str, required=True, help='BODA model module to fit dataset.')\n",
    "group.add_argument('--graph_module',type=str, required=True, help='BODA graph module to define computations.')\n",
    "group.add_argument('--artifact_path', type=str, default='/opt/ml/checkpoints/', help='Path where model artifacts are deposited.')\n",
    "group.add_argument('--pretrained_weights', type=str, help='Pretrained weights.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_args, leftover_args = parser.parse_known_args(\n",
    "    cmd_str.rstrip().split()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(artifact_path='/opt/ml/output', data_module='BODA2_DataModule', graph_module='CNNBasicTraining', model_module='Basset', pretrained_weights=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract first-order submodule args\n",
    "\n",
    "Get submodule specific arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data  = getattr(boda.data,  known_args.data_module)\n",
    "Model = getattr(boda.model, known_args.model_module)\n",
    "Graph = getattr(boda.graph, known_args.graph_module)\n",
    "\n",
    "parser = Data.add_data_specific_args(parser)\n",
    "parser = Model.add_model_specific_args(parser)\n",
    "parser = Graph.add_graph_specific_args(parser)\n",
    "\n",
    "known_args, leftover_args = parser.parse_known_args(\n",
    "    cmd_str.rstrip().split()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(TestSize_pct=5.0, ValSize_pct=5.0, activityColumns=['K562', 'HepG2', 'SKNSH'], artifact_path='/opt/ml/output', batchSize=32, conv1_channels=300, conv1_kernel_size=19, conv2_channels=200, conv2_kernel_size=11, conv3_channels=200, conv3_kernel_size=7, dataFile_path='../../data/BODA.MPRA.txt', data_module='BODA2_DataModule', dropout_p=0.3, graph_module='CNNBasicTraining', linear1_channels=1000, linear2_channels=1000, loss_criterion='MSELoss', model_module='Basset', n_outputs=3, numWorkers=1, optimizer='Adam', paddedSeqLen=600, pretrained_weights=None, scheduler=None, scheduler_interval='epoch', scheduler_monitor=None, sequenceColumn='nt.sequence', use_batch_norm=True, use_weight_norm=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract second-order submodule args\n",
    "\n",
    "Get another set of submodule specific arguments based preliminary choices. (i.e., optional arguments for optimizer of choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Data.add_conditional_args(parser, known_args)\n",
    "parser = Model.add_conditional_args(parser, known_args)\n",
    "parser = Graph.add_conditional_args(parser, known_args)\n",
    "\n",
    "parser = Trainer.add_argparse_args(parser)\n",
    "parser.add_argument('--help', '-h', action='help')\n",
    "args = parser.parse_args(\n",
    "    cmd_str.rstrip().split()\n",
    ")\n",
    "\n",
    "args = boda.common.utils.organize_args(parser, args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positional arguments': Namespace(),\n",
       " 'optional arguments': Namespace(help=None),\n",
       " 'Main args': Namespace(artifact_path='/opt/ml/output', data_module='BODA2_DataModule', graph_module='CNNBasicTraining', model_module='Basset', pretrained_weights=None),\n",
       " 'Data Module args': Namespace(TestSize_pct=5.0, ValSize_pct=5.0, activityColumns=['K562', 'HepG2', 'SKNSH'], batchSize=32, dataFile_path='../../data/BODA.MPRA.txt', numWorkers=1, paddedSeqLen=600, sequenceColumn='nt.sequence'),\n",
       " 'Model Module args': Namespace(conv1_channels=300, conv1_kernel_size=19, conv2_channels=200, conv2_kernel_size=11, conv3_channels=200, conv3_kernel_size=7, dropout_p=0.3, linear1_channels=1000, linear2_channels=1000, loss_criterion='MSELoss', n_outputs=3, use_batch_norm=True, use_weight_norm=False),\n",
       " 'Graph Module args': Namespace(optimizer='Adam', scheduler=None, scheduler_interval='epoch', scheduler_monitor=None),\n",
       " 'Optimizer args': Namespace(amsgrad=False, beta1=0.9, beta2=0.999, eps=1e-08, lr=0.001, weight_decay=0.0),\n",
       " 'pl.Trainer': Namespace(accelerator=None, accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, benchmark=False, check_val_every_n_epoch=1, checkpoint_callback=True, default_root_dir='/tmp/output/artifacts', deterministic=False, distributed_backend=None, fast_dev_run=False, flush_logs_every_n_steps=100, gpus=1, gradient_clip_algorithm='norm', gradient_clip_val=0.0, limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, max_epochs=5, max_steps=None, max_time=None, min_epochs=5, min_steps=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=1, num_sanity_val_steps=2, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=None, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, stochastic_weight_avg=False, sync_batchnorm=False, terminate_on_nan=False, tpu_cores=None, track_grad_norm=-1, truncated_bptt_steps=None, val_check_interval=1.0, weights_save_path=None, weights_summary='top')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training\n",
    "Do line-by-line first to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding sequences and converting to one-hot tensors...\n",
      "10000/27719 sequences padded and tokenized...\n",
      "20000/27719 sequences padded and tokenized...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params\n",
      "---------------------------------------------\n",
      "0  | pad1      | ConstantPad1d | 0     \n",
      "1  | conv1     | Conv1dNorm    | 23.7 K\n",
      "2  | pad2      | ConstantPad1d | 0     \n",
      "3  | conv2     | Conv1dNorm    | 660 K \n",
      "4  | pad3      | ConstantPad1d | 0     \n",
      "5  | conv3     | Conv1dNorm    | 280 K \n",
      "6  | pad4      | ConstantPad1d | 0     \n",
      "7  | maxpool_3 | MaxPool1d     | 0     \n",
      "8  | maxpool_4 | MaxPool1d     | 0     \n",
      "9  | linear1   | LinearNorm    | 2.6 M \n",
      "10 | linear2   | LinearNorm    | 1.0 M \n",
      "11 | output    | Linear        | 3.0 K \n",
      "12 | nonlin    | ReLU          | 0     \n",
      "13 | dropout   | Dropout       | 0     \n",
      "14 | criterion | MSELoss       | 0     \n",
      "---------------------------------------------\n",
      "4.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.6 M     Total params\n",
      "18.296    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4573903 parameters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a9132a666845a99af4566d724827e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_module, model_module, graph_module, model, trainer, args = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_model(data_module, model_module, graph_module, \n",
    "            model, trainer, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevent submodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = getattr(boda.data, args['Main args'].data_module)\n",
    "model_module= getattr(boda.model, args['Main args'].model_module)\n",
    "graph_module= getattr(boda.graph, args['Main args'].graph_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_module(**vars(data_module.process_args(args)))\n",
    "model= model_module(**vars(model_module.process_args(args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__class__ = type(\n",
    "    'BODA_module',\n",
    "    (model_module,graph_module),\n",
    "    vars(graph_module.process_args(args))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/tmp/output/artifacts', exist_ok=True)\n",
    "trainer = Trainer.from_argparse_args(args['optional arguments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.randn(2,4,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_model(data_module, model_module, graph_module, \n",
    "            model, trainer, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = getattr(boda, args['Main args'].data_module)\n",
    "model_module= getattr(boda, args['Main args'].model_module)\n",
    "graph_module= getattr(boda, args['Main args'].graph_module)\n",
    "\n",
    "data = data_module(**data_module.process_args(args))\n",
    "model= model_module(**model_module.process_args(args))\n",
    "\n",
    "model.__class__ = type(\n",
    "    'BODA_module',\n",
    "    (model_module,graph_module),\n",
    "    graph_module.process_args(args)\n",
    ")\n",
    "\n",
    "os.makedirs('/tmp/output/artifacts', exist_ok=True)\n",
    "trainer = Trainer.from_argparse_args(args['positional arguments'])\n",
    "trainer.default_root_dir = '/tmp/output/artifacts'\n",
    "\n",
    "trainer.fit(model, data)\n",
    "\n",
    "_save_model(data_module, model_module, graph_module, \n",
    "            model, trainer, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
