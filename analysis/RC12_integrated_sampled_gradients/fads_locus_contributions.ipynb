{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "typical-classics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "import shutil\n",
    "import random\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (random_split, DataLoader, TensorDataset, ConcatDataset)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "from Bio import motifs\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "import boda\n",
    "from boda.common import constants, utils\n",
    "\n",
    "boda_src = os.path.join( os.path.dirname( os.path.dirname( os.getcwd() ) ), 'src' )\n",
    "sys.path.insert(0, boda_src)\n",
    "\n",
    "from main import unpack_artifact, model_fn\n",
    "from pymeme import streme, parse_streme_output\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "from boda.generator.plot_tools import matrix_to_dms, ppm_to_IC, ppm_to_pwm, counts_to_ppm\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gentle-candle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20211113_021200 in eval mode\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "archive unpacked in ./\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('./artifacts'):\n",
    "    shutil.rmtree('./artifacts')\n",
    "hpo_rec = 'gs://syrgoth/aip_ui_test/model_artifacts__20211113_021200__287348.tar.gz'\n",
    "unpack_artifact(hpo_rec)\n",
    "\n",
    "model_dir = './artifacts'\n",
    "model = model_fn(model_dir)\n",
    "#model.cuda()\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "looking-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mpra_predictor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 pred_idx=0,\n",
    "                 ini_in_len=200,\n",
    "                 model_in_len=600,\n",
    "                 cat_axis=-1):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.pred_idx = pred_idx\n",
    "        self.ini_in_len = ini_in_len \n",
    "        self.model_in_len = model_in_len\n",
    "        self.cat_axis = cat_axis       \n",
    "        \n",
    "        try: self.model.eval()\n",
    "        except: pass\n",
    "        \n",
    "        self.register_flanks()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pieces = [self.left_flank.repeat(x.shape[0], 1, 1), x, self.right_flank.repeat(x.shape[0], 1, 1)]\n",
    "        in_tensor = torch.cat( pieces, axis=self.cat_axis)\n",
    "        out_tensor = self.model(in_tensor)[:, self.pred_idx]\n",
    "        return out_tensor\n",
    "    \n",
    "    def register_flanks(self):\n",
    "        missing_len = self.model_in_len - self.ini_in_len\n",
    "        left_idx = - missing_len//2 + missing_len%2\n",
    "        right_idx = missing_len//2 + missing_len%2\n",
    "        left_flank = utils.dna2tensor(constants.MPRA_UPSTREAM[left_idx:]).unsqueeze(0)\n",
    "        right_flank = utils.dna2tensor(constants.MPRA_DOWNSTREAM[:right_idx]).unsqueeze(0)         \n",
    "        self.register_buffer('left_flank', left_flank)\n",
    "        self.register_buffer('right_flank', right_flank) \n",
    "\n",
    "        \n",
    "def df_to_onehot_tensor(in_df, seq_column='sequence'):\n",
    "    onehot_sequences = torch.stack([utils.dna2tensor(subsequence) \\\n",
    "                                for subsequence in tqdm(in_df[seq_column])])\n",
    "    return onehot_sequences\n",
    "\n",
    "def fasta_to_tensor(file_name):\n",
    "    fasta_dict = {}\n",
    "    with open(file_name, 'r') as f:\n",
    "        for line in f:\n",
    "            line_str = str(line)\n",
    "            if line_str[0] == '>':\n",
    "                my_id = line_str.lstrip('>').rstrip('\\n')\n",
    "                fasta_dict[my_id] = ''\n",
    "            else:\n",
    "                fasta_dict[my_id] += line_str.rstrip('\\n')\n",
    "    seq_tensors = []\n",
    "    for sequence in list(fasta_dict.values()):\n",
    "        seq_tensors.append(utils.dna2tensor(sequence))\n",
    "    return torch.stack(seq_tensors, dim=0)\n",
    "\n",
    "def dna2tensor_approx(sequence_str, vocab_list=constants.STANDARD_NT, N_value=0.25):\n",
    "    seq_tensor = np.zeros((len(vocab_list), len(sequence_str)))\n",
    "    for letterIdx, letter in enumerate(sequence_str):\n",
    "        try:\n",
    "            seq_tensor[vocab_list.index(letter), letterIdx] = 1\n",
    "        except:\n",
    "            seq_tensor[:, letterIdx] = N_value\n",
    "    seq_tensor = torch.Tensor(seq_tensor)\n",
    "    return seq_tensor\n",
    "\n",
    "def frame_print(string, marker='*', left_space=25):\n",
    "    left_spacer = left_space * ' '\n",
    "    string = marker + ' ' + string.upper() + ' ' + marker\n",
    "    n = len(string)\n",
    "    print('', flush=True)\n",
    "    print('', flush=True)\n",
    "    print(left_spacer + n * marker, flush=True)\n",
    "    print(left_spacer + string, flush=True)\n",
    "    print(left_spacer + n * marker, flush=True)\n",
    "    print('', flush=True)\n",
    "    print('', flush=True)\n",
    "    \n",
    "def decor_print(string):\n",
    "    decor = 15*'-'\n",
    "    print('', flush=True)\n",
    "    print(decor + ' ' + string + ' ' + decor, flush=True)\n",
    "    print('', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "radical-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isg_contributions(sequences,\n",
    "                      predictor,\n",
    "                      num_steps=50,\n",
    "                      num_samples=20,\n",
    "                      eval_batch_size=1024,\n",
    "                      theta_factor=15):\n",
    "    \n",
    "    batch_size = eval_batch_size // num_samples\n",
    "    temp_dataset = TensorDataset(sequences)\n",
    "    temp_dataloader = DataLoader(temp_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    all_salient_maps = []\n",
    "    for local_batch in tqdm(temp_dataloader):\n",
    "        target_thetas = (theta_factor * local_batch[0].cuda()).requires_grad_()\n",
    "        line_gradients = []\n",
    "        for i in range(0, num_steps + 1):\n",
    "            point_thetas = (i / num_steps * target_thetas)\n",
    "            point_distributions = F.softmax(point_thetas, dim=-2)\n",
    "\n",
    "            nucleotide_probs = Categorical(torch.transpose(point_distributions, -2, -1))\n",
    "            sampled_idxs = nucleotide_probs.sample((num_samples, ))\n",
    "            sampled_nucleotides_T = F.one_hot(sampled_idxs, num_classes=4)\n",
    "            sampled_nucleotides = torch.transpose(sampled_nucleotides_T, -2, -1)\n",
    "            distribution_repeater = point_distributions.repeat(num_samples, *[1 for i in range(3)])\n",
    "            sampled_nucleotides = sampled_nucleotides - distribution_repeater.detach() + distribution_repeater \n",
    "            samples = sampled_nucleotides.flatten(0,1)\n",
    "\n",
    "            preds = predictor(samples)\n",
    "            point_predictions = preds.unflatten(0, (num_samples, target_thetas.shape[0])).mean(dim=0)\n",
    "            point_gradients = torch.autograd.grad(point_predictions.sum(), inputs=point_thetas, retain_graph=True)[0]\n",
    "            line_gradients.append(point_gradients)\n",
    "            \n",
    "        gradients = torch.stack(line_gradients).mean(dim=0) \n",
    "        all_salient_maps.append(gradients * target_thetas)\n",
    "    return torch.cat(all_salient_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chemical-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "k562_predictor = mpra_predictor(model=model, pred_idx=0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exciting-railway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr11:61,787,129-61,898,547\n"
     ]
    }
   ],
   "source": [
    "left_pad = 200\n",
    "right_pad = 200\n",
    "locus_chr = '11'\n",
    "locus_start = 61787329 - left_pad\n",
    "locus_end = 61898348 + right_pad - 1\n",
    "locus_coord = 'chr' + locus_chr + ':'+ f'{locus_start:,}' + '-' + f'{locus_end:,}'\n",
    "print(locus_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "backed-danger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111019 111019\n"
     ]
    }
   ],
   "source": [
    "#! gsutil cp gs://syrgoth/data/locus_select/chr11-61,787,129-61,898,547.txt ./\n",
    "\n",
    "locus_file = 'chr11-61,787,129-61,898,547.txt'\n",
    "locus_str = ''\n",
    "with open(locus_file) as f:\n",
    "    for line in f:\n",
    "        if line[0] != '>':\n",
    "            locus_str += line.strip()\n",
    "            \n",
    "print(len(locus_str[left_pad:-right_pad]), len(range(61787329, 61898348)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "seeing-plate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 111419])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locus_tensor = dna2tensor_approx(locus_str, N_value=0.)\n",
    "locus_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "equivalent-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create windows\n",
    "window_len = 200\n",
    "step_size = 10\n",
    "locus_tensor_windows = [locus_tensor[:, start:start+window_len] for start in range(0, locus_tensor.shape[1]-window_len+1, step_size)]\n",
    "locus_tensor_windows = torch.stack(locus_tensor_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "incorporate-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_coordinates = [f'chr{locus_chr}:{locus_start + start}-{locus_start + start + window_len-1}' for start in range(0, locus_tensor.shape[1]-window_len+1, step_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lucky-lewis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1020, 4, 200])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_example = locus_tensor_windows[:1020,...]\n",
    "chunk_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "running-apartment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved at fads_locus/contributions_v1\n",
      "\n",
      "\n",
      "--------------- Processing chunk 1/2 ---------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26645f0785634204a19a031d0856f7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contributions saved in fads_locus/contributions_v1/fads_locus_contributions__k562__window_len_200__step_size_10__chr11:61787129-61842928.pt\n",
      "\n",
      "Chunk processing time: 0:09:16.025981\n",
      "\n",
      "Estimated time remaining: 0:09:16.025981\n",
      "\n",
      "\n",
      "--------------- Processing chunk 2/2 ---------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a8e3696a8a4f6eaf9f76fa88172be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contributions saved in fads_locus/contributions_v1/fads_locus_contributions__k562__window_len_200__step_size_10__chr11:61842739-61898538.pt\n",
      "\n",
      "Chunk processing time: 0:09:16.687396\n",
      "\n",
      "Estimated time remaining: 0:00:00\n",
      "\n",
      "CPU times: user 18min 31s, sys: 1.68 s, total: 18min 33s\n",
      "Wall time: 18min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_tensor = locus_tensor_windows #locus_tensor_windows\n",
    "chunk_size = 5561 #10002 #204\n",
    "eval_batch_size = 1040\n",
    "\n",
    "cell_type = 'k562'\n",
    "targetdir = 'fads_locus/contributions_v1'\n",
    "\n",
    "print(f'Results will be saved at {targetdir}', flush=True)\n",
    "print('', flush=True)\n",
    "\n",
    "num_chunks = math.ceil(data_tensor.shape[0] / chunk_size)\n",
    "processed_chunks = 0\n",
    "for i in range(0, data_tensor.shape[0], chunk_size):\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    decor_print(f'Processing chunk {processed_chunks+1}/{num_chunks}')\n",
    "        \n",
    "    chunk = data_tensor[i:i + chunk_size, ...]    \n",
    "    \n",
    "    salient_maps = isg_contributions(chunk, k562_predictor, eval_batch_size=eval_batch_size)\n",
    "    coordinate_list = windows_coordinates[i:i + chunk.shape[0]]\n",
    "    \n",
    "    save_dict = {}\n",
    "    save_dict['window_contributions'] = salient_maps\n",
    "    save_dict['window_coordinates'] = coordinate_list\n",
    "    \n",
    "    first_coordinate = coordinate_list[0].split('-')[0]\n",
    "    last_coordinate = coordinate_list[-1].split('-')[1]\n",
    "    chunk_name = f'fads_locus_contributions__{cell_type}__window_len_{window_len}__step_size_{step_size}'\n",
    "    chunk_name += f'__{first_coordinate}-{last_coordinate}' + '.pt'\n",
    "    \n",
    "    save_path = os.path.join(targetdir, chunk_name)   \n",
    "    torch.save(save_dict, save_path)\n",
    "    \n",
    "    print(f'Contributions saved in {save_path}')\n",
    "    print('', flush=True)\n",
    "    \n",
    "    processed_chunks += 1\n",
    "    left_chunks = num_chunks - processed_chunks\n",
    "    end_time = datetime.now()\n",
    "    chunk_time = end_time - start_time\n",
    "    \n",
    "    print(f'Chunk processing time: {chunk_time}', flush=True)\n",
    "    print('', flush=True)\n",
    "    print(f'Estimated time remaining: {chunk_time*left_chunks}', flush=True)\n",
    "    print('', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-radiation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
