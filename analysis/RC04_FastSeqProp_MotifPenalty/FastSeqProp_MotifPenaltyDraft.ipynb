{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "from Bio import motifs\n",
    "\n",
    "import boda\n",
    "from boda.generator.parameters import StraightThroughParameters\n",
    "from boda.generator import FastSeqProp\n",
    "from boda.generator.plot_tools import matrix_to_dms, ppm_to_IC\n",
    "from boda.model.mpra_basset import MPRA_Basset\n",
    "from boda.common import constants\n",
    "\n",
    "boda_src = os.path.join( os.path.dirname( os.path.dirname( os.getcwd() ) ), 'src' )\n",
    "sys.path.insert(0, boda_src)\n",
    "\n",
    "from main import unpack_artifact, model_fn\n",
    "from pymeme import streme, parse_streme_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------- HPO model -----------------------\n",
    "if os.path.isdir('./artifacts'):\n",
    "    shutil.rmtree('./artifacts')\n",
    "hpo_rec = 'gs://syrgoth/aip_ui_test/model_artifacts__20210623_102310__205717.tar.gz'\n",
    "unpack_artifact(hpo_rec)\n",
    "\n",
    "model_dir = './artifacts'\n",
    "hpo_model = model_fn(model_dir)\n",
    "hpo_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------- Artisanal model -----------------------\n",
    "! gsutil cp gs://syrgoth/checkpoints/manual_checkpoint_multioutput_lasthidden250_L1.ckpt ./\n",
    "\n",
    "artisan_model = MPRA_Basset(extra_hidden_size = 250)\n",
    "checkpoint = torch.load('manual_checkpoint_multioutput_lasthidden250_L1.ckpt')\n",
    "artisan_model.load_state_dict(checkpoint['state_dict'])\n",
    "artisan_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_flank = boda.common.utils.dna2tensor( \n",
    "    boda.common.constants.MPRA_UPSTREAM[-200:] \n",
    ").unsqueeze(0)\n",
    "\n",
    "right_flank= boda.common.utils.dna2tensor( \n",
    "    boda.common.constants.MPRA_DOWNSTREAM[:200] \n",
    ").unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def castro_reward(x):\n",
    "    return torch.exp(-x) - x - 1\n",
    "\n",
    "def basic_reward(x):\n",
    "    return x\n",
    "\n",
    "def k562_score(x):\n",
    "    return -castro_reward(x[:,0]) + 0.5 * (castro_reward( x[:,1]) + castro_reward( x[:,2]))\n",
    "# def k562_score(x):\n",
    "#     return x[:,0] - torch.mean(x[:,1:], axis=1) \n",
    "def k562_specific(x):\n",
    "    scores = k562_score(x)\n",
    "    return torch.mean(-scores)\n",
    "\n",
    "def hepg2_score(x):\n",
    "    return -castro_reward(x[:,1]) + 0.5 * (castro_reward( x[:,2]) + castro_reward( x[:,0]))\n",
    "# def hepg2_score(x):\n",
    "#     return x[:,1] - torch.mean(x[:, np.r_[0,2]], axis=1)\n",
    "def hepg2_specific(x):\n",
    "    scores = hepg2_score(x)\n",
    "    return torch.mean(- scores)\n",
    "\n",
    "class mpra_energy(nn.Module):\n",
    "    def __init__(self,\n",
    "                 predictor,\n",
    "                 loss_fn,\n",
    "                 **kwrags):\n",
    "        super().__init__()\n",
    "        self.predictor = predictor\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        try: self.predictor.eval()\n",
    "        except: pass\n",
    "               \n",
    "    def forward(self, x):\n",
    "        preds = self.predictor(x)\n",
    "        return self.loss_fn(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing entropy distributions between Affine and No-Affine\n",
    "\n",
    "batch_size = 50\n",
    "sample_takes = 10\n",
    "n_samples = 10\n",
    "num_steps = 300\n",
    "scheduler = False\n",
    "\n",
    "loss_fn = hepg2_specific\n",
    "model = hpo_model #hpo_model or artisan_model\n",
    "\n",
    "energy = mpra_energy(predictor=model,\n",
    "                     loss_fn=loss_fn)\n",
    "\n",
    "#--------------------- Affine ------------------------\n",
    "theta_ini = torch.randn(batch_size, 4, 200)\n",
    "params = StraightThroughParameters(data=theta_ini,\n",
    "                                   left_flank=left_flank,\n",
    "                                   right_flank=right_flank,\n",
    "                                   n_samples=n_samples,\n",
    "                                   affine=True)\n",
    "generator = FastSeqProp(energy_fn=energy,\n",
    "                        params=params)\n",
    "generator.cuda()\n",
    "generator.run(steps=num_steps,\n",
    "              learning_rate=0.5,\n",
    "              step_print=20,\n",
    "              lr_scheduler=scheduler)\n",
    "\n",
    "entropies_affine = []\n",
    "for i in range(sample_takes):\n",
    "    preds = energy.predictor(params())\n",
    "    entropies_affine += list(boda.graph.utils.shannon_entropy(preds).detach().log().cpu().numpy())\n",
    "\n",
    "#--------------------- No Affine ------------------------\n",
    "theta_ini = torch.randn(batch_size, 4, 200)\n",
    "params = StraightThroughParameters(data=theta_ini,\n",
    "                                   left_flank=left_flank,\n",
    "                                   right_flank=right_flank,\n",
    "                                   n_samples=n_samples,\n",
    "                                   affine=False)\n",
    "generator = FastSeqProp(energy_fn=energy,\n",
    "                        params=params)\n",
    "generator.cuda()\n",
    "generator.run(steps=num_steps,\n",
    "              learning_rate=0.05,\n",
    "              step_print=20,\n",
    "              lr_scheduler=scheduler)\n",
    "\n",
    "entropies_no_affine = []\n",
    "for i in range(sample_takes):\n",
    "    preds = energy.predictor(params())\n",
    "    entropies_no_affine += list(boda.graph.utils.shannon_entropy(preds).detach().log().cpu().numpy())\n",
    "\n",
    "df_1 = pd.DataFrame(entropies_affine, columns=['entropy'])\n",
    "df_1['type'] = 'Affine'\n",
    "df_2 = pd.DataFrame(entropies_no_affine, columns=['entropy'])\n",
    "df_2['type'] = 'No affine'\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "sns.displot(data=df, x='entropy', hue='type', kind='kde', fill=True, height=7, aspect=10/6)\n",
    "#plt.xlim(0, 1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.preds.unflatten(0, (n_samples, batch_size)).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating multiple mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#------------------ Choose settings ------------------\n",
    "affine_trans = False\n",
    "iterations = 20\n",
    "batch_size = 50\n",
    "#sample_takes = 10\n",
    "n_samples = 20\n",
    "num_steps = 300\n",
    "scheduler = True\n",
    "loss_plots = False\n",
    "\n",
    "loss_fn = k562_specific\n",
    "model = artisan_model     #hpo_model or artisan_model\n",
    "\n",
    "#------------------ Optimization run ------------------\n",
    "energy = mpra_energy(predictor=model,\n",
    "                     loss_fn=loss_fn)\n",
    "\n",
    "distributions = []\n",
    "sequence_samples = []\n",
    "predictions = []\n",
    "entropies = []\n",
    "for iteration in range(iterations):\n",
    "    theta_ini = torch.randn(batch_size, 4, 200)\n",
    "    params = StraightThroughParameters(data=theta_ini,\n",
    "                                       left_flank=left_flank,\n",
    "                                       right_flank=right_flank,\n",
    "                                       n_samples=n_samples,\n",
    "                                       affine=affine_trans)\n",
    "    generator = FastSeqProp(energy_fn=energy,\n",
    "                            params=params)\n",
    "    generator.cuda()\n",
    "    generator.run(steps=num_steps,\n",
    "                  learning_rate=0.5,\n",
    "                  step_print=20,\n",
    "                  lr_scheduler=scheduler,\n",
    "                  create_plot=loss_plots)\n",
    "       \n",
    "    samples = params()\n",
    "    preds = energy.predictor(samples)\n",
    "    \n",
    "    distributions.append(params.get_probs().detach().cpu())    \n",
    "    sequence_samples.append(samples.detach().cpu().unflatten(0, (n_samples, batch_size)))\n",
    "    predictions.append(preds.detach().cpu().unflatten(0, (n_samples, batch_size)))\n",
    "    entropies.append(boda.graph.utils.shannon_entropy(preds).detach().cpu().unflatten(0, (n_samples, batch_size)))\n",
    "\n",
    "entropy_tensor = torch.cat(entropies, dim=1)\n",
    "prediction_tensor = torch.cat(predictions, dim=1)\n",
    "sequences_tensor = torch.cat(sequence_samples, dim=1)\n",
    "distributions_tensor = torch.cat(distributions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------ Select best sequences ------------------\n",
    "best_entropy_idxs = torch.argmin(entropy_tensor, dim=0)\n",
    "best_entropies = []\n",
    "best_predictions = []\n",
    "best_sequences = []\n",
    "for idx, best_idx in enumerate(best_entropy_idxs.tolist()):\n",
    "    best_entropies.append(entropy_tensor[best_idx, idx])\n",
    "    best_predictions.append(prediction_tensor[best_idx, idx, :])\n",
    "    best_sequences.append(sequences_tensor[best_idx, idx, :, 200:400])\n",
    "    \n",
    "best_entropies = torch.tensor(best_entropies)\n",
    "best_predictions = torch.stack(best_predictions, dim=0)\n",
    "best_sequences = torch.stack(best_sequences, dim=0)\n",
    "\n",
    "#------------------ Plot entropy distribution ------------------\n",
    "sns.displot(data=best_entropies, kind='kde', fill=True, height=5, aspect=10/6)\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('Entropy')\n",
    "plt.show()\n",
    "\n",
    "#------------------ Plot activities in 3D ------------------\n",
    "xdata = best_predictions[:,0].cpu().detach().numpy()\n",
    "ydata = best_predictions[:,1].cpu().detach().numpy()\n",
    "zdata = best_predictions[:,2].cpu().detach().numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "xAxisLine = ((-2, 8), (0, 0), (0,0))\n",
    "ax.plot(xAxisLine[0], xAxisLine[1], xAxisLine[2], 'r')\n",
    "yAxisLine = ((0, 0), (-2, 8), (0,0))\n",
    "ax.plot(yAxisLine[0], yAxisLine[1], yAxisLine[2], 'r')\n",
    "zAxisLine = ((0, 0), (0,0), (-2, 8))\n",
    "ax.plot(zAxisLine[0], zAxisLine[1], zAxisLine[2], 'r')\n",
    "\n",
    "ax.scatter3D(xdata, ydata, zdata, c='blue')\n",
    "ax.set_xlabel(\\\"K562\\\")\n",
    "ax.set_ylabel(\\\"HepG2\\\")\n",
    "ax.set_zlabel(\\\"SKNSH\\\")\n",
    "ax.view_init(15, -45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'k562_1000dist_castro.txt'\n",
    "batch2fasta(best_sequences, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyse with STREME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'k562_1000dist_castro.txt'\n",
    "test_seq_file = '/home/ubuntu/boda2/analysis/RC04_FastSeqProp_MotifPenalty/' + file_name\n",
    "\n",
    "streme_results = streme(test_seq_file)\n",
    "for i, line in enumerate(streme_results['output'].decode(\"utf-8\").split('\\n')):\n",
    "    print(line)                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = parse_streme_output(streme_results['output'])\n",
    "print(parsed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tensor = ppm_to_IC(torch.tensor(parsed_output['motif_results'][0]['ppm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_to_dms(ppm_to_IC(temp_tensor), y_max=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
