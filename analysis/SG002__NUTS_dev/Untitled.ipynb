{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as ag\n",
    "from torch.distributions.categorical import Categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicParameters(nn.Module):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 left_flank=None,\n",
    "                 right_flank=None,\n",
    "                 batch_dim=0,\n",
    "                 cat_axis=-1\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.register_parameter('theta', data)\n",
    "        self.register_buffer('left_flank', left_flank)\n",
    "        self.register_buffer('right_flank', right_flank)\n",
    "        \n",
    "        self.cat_axis = cat_axis\n",
    "        self.batch_dim = batch_dim\n",
    "        \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self().shape\n",
    "\n",
    "    def forward(self):\n",
    "        my_attr = [ getattr(self, x) for x in ['theta', 'left_flank', 'right_flank'] ]\n",
    "        return torch.cat( [ x for x in my_attr if x is not None ], axis=self.cat_axis )\n",
    "    \n",
    "    def rebatch(self, input):\n",
    "        return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NUTS3(nn.Module):\n",
    "    def __init__(self,\n",
    "                 params,\n",
    "                 energy_fn,\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.energy_fn  = energy_fn\n",
    "        \n",
    "        self.d_max = 1000.\n",
    "        \n",
    "    def calc_energy(self):\n",
    "        energy = self.energy_fn(self.params())\n",
    "        energy = self.params.rebatch( energy )\n",
    "        return energy\n",
    "\n",
    "    def leapfrog(self, theta, r, epsilon):\n",
    "        \n",
    "        self.params.theta.data = theta\n",
    "        energy = self.calc_energy()\n",
    "        grad_U = ag.grad( energy.sum(), self.params.theta )[0]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            r = r - grad_U.mul(epsilon).div(2.)\n",
    "            \n",
    "            theta = theta + r.mul(epsilon)\n",
    "            \n",
    "        self.params.theta.data = theta\n",
    "        energy = self.calc_energy()\n",
    "        grad_U = ag.grad( energy.sum(), self.params.theta )[0]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            r = r - grad_U.mul(epsilon).div(2.)\n",
    "            \n",
    "        return theta, r, energy\n",
    "        \n",
    "    def buildtree(self, theta, r, u, v, j, epsilon):\n",
    "        if j == 0:\n",
    "            theta_p, r_p, energy_p = self.leapfrog(theta, r, epsilon)\n",
    "            batch_dot = torch.einsum('bs,bs->b', r_p.flatten(1), r_p.flatten(1))\n",
    "            hamilton  = energy_p + batch_dot.div(2.)\n",
    "            n_p = (u <= torch.exp(-hamilton)).type(torch.long)\n",
    "            s_p = (torch.log(u).add(-self.d_max) < -hamilton).type(torch.long)\n",
    "            return theta_p, r_p, theta_p, r_p, theta_p, n_p, s_p\n",
    "        \n",
    "        else:\n",
    "            bt_pack = self.buildtree(theta, r, u, v, j-1, epsilon)\n",
    "            theta_r, r_r, theta_f, r_f, theta_p, n_p, s_p = bt_pack\n",
    "            if s_p.sum() > 0:\n",
    "                if v == -1:\n",
    "                    bt_pack = self.buildtree(theta_r, r_r, u, v, j-1, epsilon)\n",
    "                    theta_r, r_r, _, _, theta_pp, n_pp, s_pp = bt_pack\n",
    "                    \n",
    "                else:\n",
    "                    bt_pack = self.buildtree(theta_f, r_f, u, v, j-1, epsilon)\n",
    "                    _, _, theta_f, r_f, theta_pp, n_pp, s_pp = bt_pack\n",
    "                \n",
    "                update_flag = torch.rand(n_pp.size(), dtype=torch.float, \n",
    "                                         layout=n_pp.layout, device=n_pp.device)\n",
    "                update_flag = update_flag < n_pp.div( n_p + n_pp )\n",
    "                update_flag = torch.logical_and(update_flag, s_p.ge(1) )\n",
    "                theta_p[ update_flag ] = theta_pp[ update_flag ]\n",
    "                s_p = s_p * s_pp * \\\n",
    "                      torch.einsum('bs,bs->b', (theta_f - theta_r).flatten(1), r_r.flatten(1)) \\\n",
    "                        .ge(0.).type(torch.long) * \\\n",
    "                      torch.einsum('bs,bs->b', (theta_f - theta_r).flatten(1), r_f.flatten(1)) \\\n",
    "                        .ge(0.).type(torch.long)\n",
    "                n_p = n_p + n_pp\n",
    "                \n",
    "            return theta_r, r_r, theta_f, r_f, theta_p, n_p, s_p\n",
    "        \n",
    "    def init_trajectory(self, theta):\n",
    "        with torch.no_grad():\n",
    "            r_0 = torch.randn_like( theta )\n",
    "            energy_0 = self.calc_energy()\n",
    "            batch_dot= torch.einsum('bs,bs->b', r_0.flatten(1), r_0.flatten(1))\n",
    "            hamilton = energy_0 + batch_dot.div(2.)\n",
    "            u   = torch.rand_like( hamilton ).mul( torch.exp(-hamilton) )\n",
    "            \n",
    "            theta_r, theta_f = theta, theta\n",
    "            r_r, r_f = r_0, r_0\n",
    "            j = 0\n",
    "            theta_m = theta\n",
    "            n = torch.ones(batch_dot.size(), dtype=torch.long, layout=batch_dot.layout, device=batch_dot.device)\n",
    "            s = torch.ones(batch_dot.size(), dtype=torch.long, layout=batch_dot.layout, device=batch_dot.device)\n",
    "        return u, theta_r, r_r, theta_f, r_f, j, theta_m, n, s\n",
    "    \n",
    "    def sample_trajectory(self, theta, epsilon):\n",
    "        u, theta_r, r_r, theta_f, r_f, j, theta_m, n, s = self.init_trajectory(theta)\n",
    "        while s.sum() >= 1:\n",
    "            v = torch.randn([1], dtype=torch.float, layout=theta.layout, device=theta.device) \\\n",
    "                  .ge(0.).mul(2.).add(-1.)\n",
    "            if v < 0:\n",
    "                theta_r, r_r, _, _, theta_p, n_p, s_p = self.buildtree(theta_r, r_r, u, v, j, epsilon)\n",
    "            else:\n",
    "                _, _, theta_f, r_f, theta_p, n_p, s_p = self.buildtree(theta_f, r_f, u, v, j, epsilon)\n",
    "            \n",
    "            update_flag = torch.minimum( n / n_p, torch.ones_like(n.type(torch.float)) ) <= torch.rand_like(n.type(torch.float))\n",
    "            update_flag = torch.logical_and( update_flag, s.ge(1) )\n",
    "            update_flag = torch.logical_and( update_flag, s_p.ge(1) )\n",
    "            theta_m[ update_flag ] = theta_p[ update_flag ]\n",
    "            \n",
    "            n = n + n_p\n",
    "            s = s * s_p * \\\n",
    "                torch.einsum('bs,bs->b', (theta_f - theta_r).flatten(1), r_r.flatten(1)) \\\n",
    "                  .ge(0.).type(torch.long) * \\\n",
    "                torch.einsum('bs,bs->b', (theta_f - theta_r).flatten(1), r_f.flatten(1)) \\\n",
    "                  .ge(0.).type(torch.long)\n",
    "            j = j + 1\n",
    "        \n",
    "        return theta_m.detach().clone()\n",
    "    \n",
    "    def collect_samples(self, epsilon, n_samples=1):\n",
    "        samples = []\n",
    "        theta_m = self.params.theta.clone().detach()\n",
    "        for m in range(n_samples):\n",
    "            theta_m = self.sample_trajectory( theta_m, epsilon )\n",
    "            samples.append( theta_m )\n",
    "        return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameters import BasicParameters\n",
    "from nuts import NUTS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_params = BasicParameters(\n",
    "    nn.Parameter(torch.randn([3,2,1])),\n",
    "    left_flank=torch.randn([3,2,2]),\n",
    "    right_flank=torch.randn([3,2,2]) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.6594e-01,  8.0312e-01, -3.0701e-01, -3.4206e-01,  6.3109e-01],\n",
       "         [ 8.7925e-01, -9.4702e-01, -1.4804e+00, -1.6634e-03,  6.1142e-01]],\n",
       "\n",
       "        [[ 2.1903e-01,  6.4296e-01,  3.7056e-02,  1.3612e+00,  1.1617e-02],\n",
       "         [ 5.1287e-01,  9.8834e-01, -6.7040e-01, -6.6214e-01,  1.4057e-01]],\n",
       "\n",
       "        [[-1.2719e+00,  5.7301e-01, -1.0352e+00, -9.8352e-01,  9.9522e-01],\n",
       "         [ 5.4203e-01, -1.7494e+00, -6.2569e-01,  1.1204e+00,  6.5439e-01]]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_params.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_energy(in_tensor):\n",
    "    return in_tensor.pow(2).mean(dim=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6240, 0.4463, 1.0405], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_energy( my_params.forward() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sampler = NUTS3( my_params, my_energy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2053],\n",
      "         [ 1.4418]],\n",
      "\n",
      "        [[ 1.6426],\n",
      "         [-0.1297]],\n",
      "\n",
      "        [[-0.5519],\n",
      "         [-0.9181]]])\n",
      "tensor([[[-0.5853],\n",
      "         [-0.2071]],\n",
      "\n",
      "        [[ 0.7339],\n",
      "         [-1.5180]],\n",
      "\n",
      "        [[-0.5162],\n",
      "         [ 1.1002]]])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.8659],\n",
      "         [ 0.8793]],\n",
      "\n",
      "        [[ 0.2190],\n",
      "         [ 0.5129]],\n",
      "\n",
      "        [[-1.2719],\n",
      "         [ 0.5420]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "test_theta = torch.randn([3,2,1])\n",
    "test_r     = torch.randn([3,2,1])\n",
    "print(test_theta)\n",
    "print(test_r)\n",
    "print(my_sampler.params.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = my_sampler.leapfrog(test_theta, test_r, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-1.2059],\n",
      "         [ 1.4416]],\n",
      "\n",
      "        [[ 1.6433],\n",
      "         [-0.1312]],\n",
      "\n",
      "        [[-0.5524],\n",
      "         [-0.9170]]]), tensor([[[-0.5851],\n",
      "         [-0.2074]],\n",
      "\n",
      "        [[ 0.7336],\n",
      "         [-1.5180]],\n",
      "\n",
      "        [[-0.5161],\n",
      "         [ 1.1003]]]), tensor([0.8249, 0.6870, 0.9639], grad_fn=<MeanBackward1>))\n",
      "tensor([[[-1.2053],\n",
      "         [ 1.4418]],\n",
      "\n",
      "        [[ 1.6426],\n",
      "         [-0.1297]],\n",
      "\n",
      "        [[-0.5519],\n",
      "         [-0.9181]]])\n",
      "tensor([[[-0.5853],\n",
      "         [-0.2071]],\n",
      "\n",
      "        [[ 0.7339],\n",
      "         [-1.5180]],\n",
      "\n",
      "        [[-0.5162],\n",
      "         [ 1.1002]]])\n",
      "Parameter containing:\n",
      "tensor([[[-1.2059],\n",
      "         [ 1.4416]],\n",
      "\n",
      "        [[ 1.6433],\n",
      "         [-0.1312]],\n",
      "\n",
      "        [[-0.5524],\n",
      "         [-0.9170]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(test_theta)\n",
    "print(test_r)\n",
    "print(my_sampler.params.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0421, 0.1706, 0.1485]),\n",
       " tensor([[[-1.2053],\n",
       "          [ 1.4418]],\n",
       " \n",
       "         [[ 1.6426],\n",
       "          [-0.1297]],\n",
       " \n",
       "         [[-0.5519],\n",
       "          [-0.9181]]]),\n",
       " tensor([[[-0.2866],\n",
       "          [ 0.1812]],\n",
       " \n",
       "         [[-0.0254],\n",
       "          [ 0.6422]],\n",
       " \n",
       "         [[ 1.1266],\n",
       "          [-0.1823]]]),\n",
       " tensor([[[-1.2053],\n",
       "          [ 1.4418]],\n",
       " \n",
       "         [[ 1.6426],\n",
       "          [-0.1297]],\n",
       " \n",
       "         [[-0.5519],\n",
       "          [-0.9181]]]),\n",
       " tensor([[[-0.2866],\n",
       "          [ 0.1812]],\n",
       " \n",
       "         [[-0.0254],\n",
       "          [ 0.6422]],\n",
       " \n",
       "         [[ 1.1266],\n",
       "          [-0.1823]]]),\n",
       " 0,\n",
       " tensor([[[-1.2053],\n",
       "          [ 1.4418]],\n",
       " \n",
       "         [[ 1.6426],\n",
       "          [-0.1297]],\n",
       " \n",
       "         [[-0.5519],\n",
       "          [-0.9181]]]),\n",
       " tensor([1, 1, 1]),\n",
       " tensor([1, 1, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_vals = my_sampler.init_trajectory(test_theta)\n",
    "check_u, check_theta_r, check_r_r, check_theta_f, check_r_f, check_j, check_theta_m, check_n, check_s = init_vals\n",
    "init_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.randn([1], dtype=torch.float, layout=test_theta.layout, device=test_theta.device) \\\n",
    "                  .ge(0.).mul(2.).add(-1.)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(check_theta_f - check_theta_r).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_r_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('bs,bs->b', (check_theta_f - check_theta_r).flatten(1), check_r_r.flatten(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2053],\n",
      "         [ 1.4418]],\n",
      "\n",
      "        [[ 1.6426],\n",
      "         [-0.1297]],\n",
      "\n",
      "        [[-0.5519],\n",
      "         [-0.9181]]])\n"
     ]
    }
   ],
   "source": [
    "print(test_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]]),\n",
       " tensor([[[-0.5805],\n",
       "          [-0.2129]],\n",
       " \n",
       "         [[ 0.7273],\n",
       "          [-1.5174]],\n",
       " \n",
       "         [[-0.5139],\n",
       "          [ 1.1038]]]),\n",
       " tensor([[[-1.2111],\n",
       "          [ 1.4397]],\n",
       " \n",
       "         [[ 1.6499],\n",
       "          [-0.1449]],\n",
       " \n",
       "         [[-0.5571],\n",
       "          [-0.9070]]]),\n",
       " tensor([[[-0.5829],\n",
       "          [-0.2100]],\n",
       " \n",
       "         [[ 0.7306],\n",
       "          [-1.5177]],\n",
       " \n",
       "         [[-0.5151],\n",
       "          [ 1.1020]]]),\n",
       " tensor([[[-1.2111],\n",
       "          [ 1.4397]],\n",
       " \n",
       "         [[ 1.6499],\n",
       "          [-0.1449]],\n",
       " \n",
       "         [[-0.5571],\n",
       "          [-0.9070]]]),\n",
       " tensor([2, 0, 2]),\n",
       " tensor([0, 0, 0]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sampler.buildtree(test_theta, test_r, init_vals[0], v, 3, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2053],\n",
      "         [ 1.4418]],\n",
      "\n",
      "        [[ 1.6426],\n",
      "         [-0.1297]],\n",
      "\n",
      "        [[-0.5519],\n",
      "         [-0.9181]]])\n"
     ]
    }
   ],
   "source": [
    "print(test_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_samples = my_sampler.collect_samples(1e-3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]]),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]]),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]]),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]]),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]]),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]]),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]]),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]]),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]]),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6572],\n",
       "          [-0.1600]],\n",
       " \n",
       "         [[-0.5622],\n",
       "          [-0.8960]]])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicParameters()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sampler.params.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.2285],\n",
       "          [ 1.4333]],\n",
       " \n",
       "         [[ 1.6717],\n",
       "          [-0.1904]],\n",
       " \n",
       "         [[-0.5725],\n",
       "          [-0.8739]]], device='cuda:0'),\n",
       " tensor([[[-0.5756],\n",
       "          [-0.2186]],\n",
       " \n",
       "         [[ 0.7206],\n",
       "          [-1.5167]],\n",
       " \n",
       "         [[-0.5117],\n",
       "          [ 1.1073]]], device='cuda:0'),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6499],\n",
       "          [-0.1449]],\n",
       " \n",
       "         [[-0.5673],\n",
       "          [-0.8850]]], device='cuda:0'),\n",
       " tensor([[[-0.5829],\n",
       "          [-0.2100]],\n",
       " \n",
       "         [[ 0.7306],\n",
       "          [-1.5177]],\n",
       " \n",
       "         [[-0.5151],\n",
       "          [ 1.1020]]], device='cuda:0'),\n",
       " tensor([[[-1.2169],\n",
       "          [ 1.4376]],\n",
       " \n",
       "         [[ 1.6499],\n",
       "          [-0.1449]],\n",
       " \n",
       "         [[-0.5673],\n",
       "          [-0.8850]]], device='cuda:0'),\n",
       " tensor([4, 0, 4], device='cuda:0'),\n",
       " tensor([0, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sampler.buildtree(test_theta.cuda(), test_r.cuda(), init_vals[0].cuda(), v.cuda(), 3, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
