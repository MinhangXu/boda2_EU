{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c6bfc5-2961-4305-8aeb-9352f12f813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "import csv\n",
    "import multiprocessing\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functorch import combine_state_for_ensemble, vmap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boda\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649cde06-1d49-413a-a5ce-940700e42093",
   "metadata": {},
   "outputs": [],
   "source": [
    "boda_src = os.path.join( os.path.dirname( os.path.dirname( os.getcwd() ) ), 'src' )\n",
    "sys.path.insert(0, boda_src)\n",
    "\n",
    "from main import unpack_artifact, model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3564347-3f40-41f6-a464-18d0e73a9e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b2268c-89eb-4c0e-a26c-b63d67947615",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_rec = 'gs://syrgoth/aip_ui_test/model_artifacts__20211113_021200__287348.tar.gz'\n",
    "fasta_fn = 'GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta' # Genome reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39200d32-61d2-4e8a-b2cf-018f3024c881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre-reading fasta into memory\n",
      "100%|██████████████████████████| 44284892/44284892 [00:16<00:00, 2684409.76it/s]\n",
      "finding keys\n",
      "parsing\n",
      "100%|█████████████████████████████████████████| 195/195 [11:35<00:00,  3.57s/it]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "fasta_dict = boda.data.Fasta(fasta_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c67c4707-9812-4d6e-99c0-d12bf0618101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vcf_fn = 'gencode.v42.500bp.promoter.cosmic.vars.vcf'\n",
    "out_fn = 'gencode.v42.500bp.promoter.cosmic.vars.pt'\n",
    "\n",
    "vcf_fn = 'all.significant.calls.k562.hepg2.rd.35.p.point.2.vcf'\n",
    "out_fn = 'all.significant.calls.k562.hepg2.rd.35.p.point.2.pt'\n",
    "\n",
    "vcf_fn = 'all.significant.calls.k562.hepg2.rd.35.p.point.2.vcf'\n",
    "out_fn = 'all.significant.calls.k562.hepg2.rd.35.p.point.2.full_vector_rc.pt'\n",
    "\n",
    "vcf_fn = 'k562.ase.calls.fdr.05.vcf'\n",
    "out_fn = 'k562.ase.calls.fdr.05.full_vector_rc.pt'\n",
    "\n",
    "vcf_fn = 'dnase.v2.all.cells.aggreg.vcf'\n",
    "out_fn = 'dnase.v2.all.cells.aggreg.pt'\n",
    "\n",
    "vcf_fn = 'hepg2.ase.calls.fdr.05.vcf'\n",
    "out_fn = 'hepg2.ase.calls.fdr.05.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f23af1b-4f47-4084-b52b-9e6bdc188563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading DataFrame\n",
      "Checking and filtering tokens\n",
      "Allele length checks\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_vcf = boda.data.VCF(vcf_fn, chr_prefix='', max_allele_size=20, max_indel_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e70e7565-5672-439a-9090-4bb5f10e57de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29374588, -0.17407839, -2.332368  ],\n",
       "       [-0.14504315,  0.01482684, -0.29215747],\n",
       "       [-1.3820796 ,  0.9389331 ,  0.24991722],\n",
       "       ...,\n",
       "       [ 0.8460486 , -1.0635027 , -1.2409896 ],\n",
       "       [ 2.0486255 , -0.82711196, -1.5808923 ],\n",
       "       [-0.7439912 , -0.0762727 ,  0.4138339 ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(499, 3).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "034ab4f2-654a-4178-997d-5f5eb8641307",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 200\n",
    "RELATIVE_START = 25\n",
    "RELATIVE_END = 180\n",
    "STEP_SIZE = 25\n",
    "REVERSE_COMPLEMENTS = True\n",
    "\n",
    "BATCH_SIZE = 16 * 1\n",
    "NUM_WORKERS= 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca840e4a-c361-4bc0-a79f-43c2a3c253e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "499/499 records have matching contig in FASTA\n",
      "returned 499/499 records\n"
     ]
    }
   ],
   "source": [
    "vcf_data = boda.data.VcfDataset(test_vcf.vcf, fasta_dict.fasta, \n",
    "                                                 WINDOW_SIZE, RELATIVE_START, RELATIVE_END, step_size=STEP_SIZE,\n",
    "                                                 reverse_complements=REVERSE_COMPLEMENTS, use_contigs=[])\n",
    "vcf_loader = torch.utils.data.DataLoader(vcf_data, batch_size=BATCH_SIZE*torch.cuda.device_count(), num_workers=NUM_WORKERS*torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37bcb534-02ca-411f-8288-da5638d14da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 4, 200])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_data[0]['ref'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6b8a35b-f334-4832-8dbb-9f46c8e21ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 4, 200])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_data[0]['ref'].unflatten(0,(2 if REVERSE_COMPLEMENTS else 1,vcf_data[0]['ref'].shape[0]//2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38c67776-3352-471b-b133-c6e4d4bf4cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACACCTGGTCCGCCCAGTCGGAACTCACCCCTACGCCGCCGCCGCTGCCGCCGCCGCCGCCGCCGGTCCCGGAGCCAGAGAAGAAACAGCAACCGGCGCGCGCCAAAAGTATCGTCACTTCCTGTATTGGCGCGTAATGATGATATAATAGCCGACCTCCGGCCCAGAACTCGAGACAACGACAGGGGCTCGCTCTGTGC\n",
      "CACCCCTACGCCGCCGCCGCTGCCGCCGCCGCCGCCGCCGGTCCCGGAGCCAGAGAAGAAACAGCAACCGGCGCGCGCCAAAAGTATCGTCACTTCCTGTATTGGCGCGTAATGATGATATAATAGCCGACCTCCGGCCCAGAACTCGAGACAACGACAGGGGCTCGCTCTGTGCGGCACTTCCTGTGTCTGCGCGGGAT\n",
      "CCGCCGCCGCCGCCGGTCCCGGAGCCAGAGAAGAAACAGCAACCGGCGCGCGCCAAAAGTATCGTCACTTCCTGTATTGGCGCGTAATGATGATATAATAGCCGACCTCCGGCCCAGAACTCGAGACAACGACAGGGGCTCGCTCTGTGCGGCACTTCCTGTGTCTGCGCGGGATGATAACGCATAAAACAGCGCTTGCT\n",
      "CAGAGAAGAAACAGCAACCGGCGCGCGCCAAAAGTATCGTCACTTCCTGTATTGGCGCGTAATGATGATATAATAGCCGACCTCCGGCCCAGAACTCGAGACAACGACAGGGGCTCGCTCTGTGCGGCACTTCCTGTGTCTGCGCGGGATGATAACGCATAAAACAGCGCTTGCTCAGGTCCAGGACGCCAGAAGAAACA\n",
      "CGCCAAAAGTATCGTCACTTCCTGTATTGGCGCGTAATGATGATATAATAGCCGACCTCCGGCCCAGAACTCGAGACAACGACAGGGGCTCGCTCTGTGCGGCACTTCCTGTGTCTGCGCGGGATGATAACGCATAAAACAGCGCTTGCTCAGGTCCAGGACGCCAGAAGAAACAGCCCGGTGAGCGCACTTCCGACTTC\n",
      "ATTGGCGCGTAATGATGATATAATAGCCGACCTCCGGCCCAGAACTCGAGACAACGACAGGGGCTCGCTCTGTGCGGCACTTCCTGTGTCTGCGCGGGATGATAACGCATAAAACAGCGCTTGCTCAGGTCCAGGACGCCAGAAGAAACAGCCCGGTGAGCGCACTTCCGACTTCGGCGCGGGCTGTGACGCAGGAATCG\n",
      "GCCGACCTCCGGCCCAGAACTCGAGACAACGACAGGGGCTCGCTCTGTGCGGCACTTCCTGTGTCTGCGCGGGATGATAACGCATAAAACAGCGCTTGCTCAGGTCCAGGACGCCAGAAGAAACAGCCCGGTGAGCGCACTTCCGACTTCGGCGCGGGCTGTGACGCAGGAATCGGGACTCCGGAGGAGCGACGCCCACT\n"
     ]
    }
   ],
   "source": [
    "for i in range(vcf_data[0]['ref'].shape[0]//2):\n",
    "    reshaped_vcf_rec = vcf_data[0]['ref'].unflatten(0,(2 if REVERSE_COMPLEMENTS else 1,vcf_data[0]['ref'].shape[0]//2))\n",
    "    print(''.join([ ['A','C','G','T'][n] for n in reshaped_vcf_rec[0,i].argmax(0) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cd5c4b1-5605-4685-8ca0-0edee02c7aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "       ... \n",
       "494    True\n",
       "495    True\n",
       "496    True\n",
       "497    True\n",
       "498    True\n",
       "Name: chrom, Length: 499, dtype: bool"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_data.vcf['chrom'].isin(fasta_dict.fasta.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07b62fca-c852-4235-a8c0-895192b1b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (n_variants, n_alleles, n_strands, n_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e96dfa7-4e91-446b-a775-d2d228359ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlankBuilder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 left_flank=None,\n",
    "                 right_flank=None,\n",
    "                 batch_dim=0,\n",
    "                 cat_axis=-1\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.register_buffer('left_flank', left_flank.detach().clone())\n",
    "        self.register_buffer('right_flank', right_flank.detach().clone())\n",
    "        \n",
    "        self.batch_dim = batch_dim\n",
    "        self.cat_axis  = cat_axis\n",
    "        \n",
    "    def add_flanks(self, my_sample):\n",
    "        *batch_dims, channels, length = my_sample.shape\n",
    "        \n",
    "        pieces = []\n",
    "        \n",
    "        if self.left_flank is not None:\n",
    "            pieces.append( self.left_flank.expand(*batch_dims, -1, -1) )\n",
    "            \n",
    "        pieces.append( my_sample )\n",
    "        \n",
    "        if self.right_flank is not None:\n",
    "            pieces.append( self.right_flank.expand(*batch_dims, -1, -1) )\n",
    "            \n",
    "        return torch.cat( pieces, axis=self.cat_axis )\n",
    "    \n",
    "    def forward(self, my_sample):\n",
    "        return self.add_flanks(my_sample)\n",
    "\n",
    "class VepTester(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                  model\n",
    "                 ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = torch.nn.DataParallel(model) if torch.cuda.device_count() > 1 else model\n",
    "        \n",
    "    def forward(self, ref_batch, alt_batch):\n",
    "        \n",
    "        ref_shape, alt_shape = ref_batch.shape, alt_batch.shape\n",
    "        assert ref_shape == alt_shape\n",
    "        \n",
    "        ref_batch = ref_batch.flatten(0,1).cuda()\n",
    "        alt_batch = alt_batch.flatten(0,1).cuda()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            ref_preds = self.model(ref_batch.contiguous())\n",
    "            alt_preds = self.model(alt_batch.contiguous())\n",
    "\n",
    "        ref_preds = ref_preds.unflatten(0, ref_shape[0:2])\n",
    "        ref_preds = ref_preds.unflatten(1, (2, ref_shape[1]//2))\n",
    "        \n",
    "        alt_preds = alt_preds.unflatten(0, alt_shape[0:2])\n",
    "        alt_preds = alt_preds.unflatten(1, (2, alt_shape[1]//2))\n",
    "            \n",
    "        skew_preds = alt_preds - ref_preds\n",
    "\n",
    "        return {'ref': ref_preds, \n",
    "                'alt': alt_preds, \n",
    "                'skew': skew_preds}\n",
    "    \n",
    "class VepTester_FullRC(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                  model\n",
    "                 ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = torch.nn.DataParallel(model) if torch.cuda.device_count() > 1 else model\n",
    "        \n",
    "    def forward(self, ref_batch, alt_batch):\n",
    "        \n",
    "        ref_shape, alt_shape = ref_batch.shape, alt_batch.shape\n",
    "        assert ref_shape == alt_shape\n",
    "        \n",
    "        ref_batch = ref_batch.flatten(0,1).cuda()\n",
    "        alt_batch = alt_batch.flatten(0,1).cuda()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            ref_preds = self.model(ref_batch.contiguous()).unflatten(0, ref_shape[0:2])\n",
    "            alt_preds = self.model(alt_batch.contiguous()).unflatten(0, ref_shape[0:2])\n",
    "            \n",
    "        with torch.cuda.amp.autocast():\n",
    "            ref_preds_rc = self.model(ref_batch.flip(dims=[-2,-1]).contiguous()).unflatten(0, ref_shape[0:2])\n",
    "            alt_preds_rc = self.model(alt_batch.flip(dims=[-2,-1]).contiguous()).unflatten(0, ref_shape[0:2])\n",
    "\n",
    "        ref_preds = torch.stack([ref_preds, ref_preds_rc], dim=1)\n",
    "        alt_preds = torch.stack([alt_preds, alt_preds_rc], dim=1)\n",
    "            \n",
    "        skew_preds = alt_preds - ref_preds\n",
    "\n",
    "        return {'ref': ref_preds, \n",
    "                'alt': alt_preds, \n",
    "                'skew': skew_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d87bd8a-531b-49ce-a2dc-d204b41a8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reductions(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean(tensor, dim):\n",
    "        return tensor.mean(dim=dim)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sum(tensor, dim):\n",
    "        return tensor.sum(dim=dim)\n",
    "    \n",
    "    @staticmethod\n",
    "    def max(tensor, dim):\n",
    "        return tensor.amax(dim=dim)\n",
    "    \n",
    "    @staticmethod\n",
    "    def min(tensor, dim):\n",
    "        return tensor.amin(dim=dim)\n",
    "    \n",
    "    @staticmethod\n",
    "    def abs_max(tensor, dim):\n",
    "        n_dims = len(tensor.shape)\n",
    "        get_idx= tensor.abs().argmax(dim=dim)\n",
    "        slicer = []\n",
    "        for i in range(n_dims):\n",
    "            if i != dim:\n",
    "                viewer = [1] * n_dims\n",
    "                dim_size = tensor.shape[i]\n",
    "                viewer[i] = dim_size\n",
    "                viewer.pop(dim)\n",
    "                slicer.append( torch.arange(dim_size).view(*viewer).expand(*get_idx.shape) )\n",
    "            else:\n",
    "                slicer.append( get_idx )\n",
    "            \n",
    "        return tensor[slicer]\n",
    "    \n",
    "    @staticmethod\n",
    "    def abs_min(tensor, dim):\n",
    "        n_dims = len(tensor.shape)\n",
    "        get_idx= tensor.abs().argmin(dim=dim)\n",
    "        slicer = []\n",
    "        for i in range(n_dims):\n",
    "            if i != dim:\n",
    "                viewer = [1] * n_dims\n",
    "                dim_size = tensor.shape[i]\n",
    "                viewer[i] = dim_size\n",
    "                viewer.pop(dim)\n",
    "                slicer.append( torch.arange(dim_size).view(*viewer).expand(*get_idx.shape) )\n",
    "            else:\n",
    "                slicer.append( get_idx )\n",
    "            \n",
    "        return tensor[slicer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0fc2d8-206e-4cb7-861b-d8173e4a503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(artifact_path):\n",
    "    \n",
    "    USE_CUDA = torch.cuda.device_count() >= 1\n",
    "    if os.path.isdir('./artifacts'):\n",
    "        shutil.rmtree('./artifacts')\n",
    "\n",
    "    unpack_artifact(artifact_path)\n",
    "\n",
    "    model_dir = './artifacts'\n",
    "\n",
    "    my_model = model_fn(model_dir)\n",
    "    my_model.eval()\n",
    "    if USE_CUDA:\n",
    "        my_model.cuda()\n",
    "    \n",
    "    return my_model\n",
    "\n",
    "class ConsistentModelPool(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 path_list\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        models = [ load_model(model_path) for model_path in path_list ]\n",
    "        self.fmodel, self.params, self.buffers = combine_state_for_ensemble(models)\n",
    "            \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        preds = vmap(self.fmodel, in_dims=(0, 0, None))(self.params, self.buffers, batch)\n",
    "        return preds.mean(dim=0)\n",
    "            \n",
    "class VariableModelPool(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 path_list\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.models = [ load_model(model_path) for model_path in path_list ]\n",
    "            \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        return torch.stack([model(batch) for model in self.models]).mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a92170f-a6b7-45ff-aa67-edae38bc0964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://syrgoth/aip_ui_test/model_artifacts__20211113_021200__287348.tar.gz...\n",
      "- [1 files][ 49.3 MiB/ 49.3 MiB]                                                \n",
      "Operation completed over 1 objects/49.3 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20211113_021200 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "archive unpacked in ./\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    my_model = ConsistentModelPool([\n",
    "        'gs://tewhey-public-data/crossval_models/models_230111/test_1_val_10/model_artifacts__20230112_024037__325298.tar.gz',\n",
    "        'gs://tewhey-public-data/crossval_models/models_230111/test_1_val_11/model_artifacts__20230112_003539__758935.tar.gz',\n",
    "        'gs://tewhey-public-data/crossval_models/models_230111/test_1_val_2/model_artifacts__20230111_192235__715916.tar.gz',\n",
    "        'gs://tewhey-public-data/crossval_models/models_230111/test_1_val_3/model_artifacts__20230111_190417__993143.tar.gz',\n",
    "        'gs://tewhey-public-data/crossval_models/models_230111/test_1_val_4/model_artifacts__20230112_000934__941678.tar.gz',\n",
    "        'gs://tewhey-public-data/crossval_models/models_230111/test_1_val_5/model_artifacts__20230112_003327__287605.tar.gz',\n",
    "        'gs://tewhey-public-data/crossval_models/models_230111/test_1_val_6/model_artifacts__20230112_020038__431749.tar.gz',\n",
    "        'gs://tewhey-public-data/crossval_models/models_230111/test_1_val_7/model_artifacts__20230112_182326__436818.tar.gz',\n",
    "        'gs://tewhey-public-data/crossval_models/models_230111/test_1_val_8/model_artifacts__20230112_014853__150994.tar.gz',\n",
    "        'gs://tewhey-public-data/crossval_models/models_230111/test_1_val_9/model_artifacts__20230111_232551__863644.tar.gz'\n",
    "    ])\n",
    "\n",
    "if True:\n",
    "    my_model = load_model(hpo_rec)\n",
    "    ckpt = torch.load('./artifacts/torch_checkpoint.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "209115ae-c0bc-4fd8-bba5-8808fa7536e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_module', 'data_hparams', 'model_module', 'model_hparams', 'graph_module', 'graph_hparams', 'model_state_dict', 'timestamp', 'random_tag'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74b7883d-c9b8-4a72-bc76-b0433c90049e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(activity_columns=['K562_mean', 'HepG2_mean', 'SKNSH_mean'], batch_size=1076, chr_column='chr', data_project=['BODA', 'UKBB', 'GTEX'], datafile_path='gs://syrgoth/data/MPRA_ALL_v3.txt', duplication_cutoff=0.5, exclude_chr_train=[''], normalize=False, num_workers=8, padded_seq_len=600, project_column='data_project', sequence_column='nt_sequence', std_multiple_cut=6.0, synth_chr='synth', synth_seed=102202, synth_test_pct=99.98, synth_val_pct=0.0, test_chrs=['7', '13'], up_cutoff_move=3.0, use_reverse_complements=True, val_chrs=['19', '21', 'X'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['data_hparams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b91305b-a49b-4fc4-886b-44c82556e7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model(torch.randn((1,4,600)).cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d3adac6-dab4-4ed1-8fce-93b9dfa65a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 200])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_flank = boda.common.utils.dna2tensor( \n",
    "    boda.common.constants.MPRA_UPSTREAM[-200:] \n",
    ").unsqueeze(0).unsqueeze(0)\n",
    "left_flank.shape\n",
    "\n",
    "right_flank= boda.common.utils.dna2tensor( \n",
    "    boda.common.constants.MPRA_DOWNSTREAM[:200] \n",
    ").unsqueeze(0).unsqueeze(0)\n",
    "right_flank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b6b774e-24eb-45a8-af7c-bf4f752f0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "flank_builder = FlankBuilder(\n",
    "    left_flank=left_flank,\n",
    "    right_flank=right_flank,\n",
    ")\n",
    "flank_builder.cuda()\n",
    "vep_tester = VepTester(my_model) if REVERSE_COMPLEMENTS else VepTester_FullRC(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b14a274-ae5f-4ab6-85cb-4d22cc141a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:696: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::max_pool1d. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at ../aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00,  8.47it/s]\n"
     ]
    }
   ],
   "source": [
    "ref_preds = []\n",
    "alt_preds = []\n",
    "skew_preds= []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm.tqdm(vcf_loader)):\n",
    "        ref_allele, alt_allele = batch['ref'], batch['alt']\n",
    "        \n",
    "        ref_allele = flank_builder(ref_allele.cuda()).contiguous()\n",
    "        alt_allele = flank_builder(alt_allele.cuda()).contiguous()\n",
    "        \n",
    "        all_preds = vep_tester(ref_allele, alt_allele)\n",
    "        \n",
    "        #ref_preds.append(all_preds['ref'].cpu())\n",
    "        #alt_preds.append(all_preds['alt'].cpu())\n",
    "        skew_preds.append(all_preds['skew'].cpu())\n",
    "\n",
    "#ref_preds = torch.cat(ref_preds, dim=0)\n",
    "#alt_preds = torch.cat(alt_preds, dim=0)\n",
    "skew_preds= torch.cat(skew_preds, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7093f9d2-d915-48b7-b981-2db047c3e8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1680, -0.0453, -0.2559],\n",
       "        [-1.3037, -0.7322, -1.1129],\n",
       "        [ 0.1487,  0.0974,  0.1986],\n",
       "        [ 0.7297,  0.7278,  0.3882],\n",
       "        [ 0.1549,  0.1276,  0.1208],\n",
       "        [-0.1534, -0.3621, -0.3195],\n",
       "        [ 0.2609,  0.2534,  0.3482],\n",
       "        [-1.8330, -1.3625, -1.8389],\n",
       "        [ 0.3339,  0.2508,  0.2232],\n",
       "        [ 0.1988,  0.2930,  0.2083],\n",
       "        [-0.2940, -0.4840, -0.5363],\n",
       "        [ 0.5022, -0.2696, -0.4596],\n",
       "        [ 1.6947,  1.0100,  0.5921],\n",
       "        [-0.1018, -0.1527, -0.2493],\n",
       "        [-0.0582,  0.0364,  0.0642],\n",
       "        [ 0.2422,  0.7290,  0.5186],\n",
       "        [ 0.0731,  0.2964, -0.0660],\n",
       "        [ 0.0966,  0.1153,  0.1246],\n",
       "        [-0.5113, -0.6667, -0.8171],\n",
       "        [-1.5726, -0.3283, -0.1331]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reductions.abs_max( skew_preds.flatten(1,2), dim=1 )[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df9ee102-f711-4131-be33-b768f5dc377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'ref': ref_preds, 'alt': alt_preds}, out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6aa7add-a8c5-40c0-9819-807f074dceca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 4, 200])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_data[0]['ref'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4381e44c-f377-45b7-a772-b53ddca2f69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3],\n",
       "        [5, 8]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10).view(2,-1)[:,::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7907b08b-eda9-4069-8c54-5055ed98b772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10).view(2,-1)[:,::4].amax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43ca0e94-00d1-4723-a601-c7363d59bbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.6856e+00,  3.4301e-01, -6.0946e-01, -1.0167e+00],\n",
       "         [ 6.7576e-01, -1.9882e+00, -3.2934e+00,  4.9012e-01],\n",
       "         [ 6.6305e-01, -8.5159e-02, -1.3291e+00, -1.7398e-01],\n",
       "         [ 2.8326e-01, -3.7289e-01,  1.1904e+00, -1.2813e+00]],\n",
       "\n",
       "        [[-1.6285e+00, -1.6911e+00,  5.5387e-02, -1.6507e+00],\n",
       "         [ 2.1087e-01, -1.1325e+00,  1.2331e+00,  2.8895e-01],\n",
       "         [ 1.8064e+00, -1.1330e-01,  2.9672e-01,  1.5957e-01],\n",
       "         [ 2.4114e-01, -1.1229e+00,  9.7628e-01, -6.5015e-01]],\n",
       "\n",
       "        [[ 4.7679e-01,  5.6372e-01,  2.8561e-01,  1.0265e+00],\n",
       "         [-6.6995e-01, -1.2969e-01,  2.1860e+00,  1.8343e+00],\n",
       "         [-1.2044e+00,  4.7310e-01,  8.5648e-01,  8.2419e-02],\n",
       "         [-4.5638e-01, -1.3656e+00,  6.9233e-01,  1.0186e-01]],\n",
       "\n",
       "        [[ 1.0010e-01,  4.2466e-01,  8.6448e-01, -8.2313e-02],\n",
       "         [-8.7955e-01,  9.1755e-01,  9.4769e-02, -1.9924e+00],\n",
       "         [-3.3751e-01,  5.4379e-01, -2.0579e+00, -3.0400e-03],\n",
       "         [ 2.4735e-01,  3.9347e-01, -1.2182e+00,  1.8204e+00]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 4, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "365eaeca-3dcc-4965-8eb7-351fa76b2303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 3, 1],\n",
       "        [2, 2, 1, 1],\n",
       "        [0, 0, 1, 1],\n",
       "        [3, 1, 0, 3]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf773820-cc26-44a5-9049-d6dfa70f38d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 1, 2, 3]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4).view(1,4).expand(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59371d25-1681-4bc6-a311-ec513ce3caf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6856, -1.9882, -3.2934, -1.2813],\n",
       "        [ 1.8064, -1.6911,  1.2331, -1.6507],\n",
       "        [-1.2044, -1.3656,  2.1860,  1.8343],\n",
       "        [-0.8795,  0.9175, -2.0579, -1.9924]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slicer = [torch.arange(4).view(4,1).expand(4,4),a.abs().argmax(dim=1), torch.arange(4).view(1,4).expand(4,4)]\n",
    "\n",
    "a[slicer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "691d0068-b133-477a-9167-2d61fc2a6b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.6856e+00,  3.4301e-01, -6.0946e-01, -1.0167e+00],\n",
       "         [ 6.7576e-01, -1.9882e+00, -3.2934e+00,  4.9012e-01],\n",
       "         [ 6.6305e-01, -8.5159e-02, -1.3291e+00, -1.7398e-01],\n",
       "         [ 2.8326e-01, -3.7289e-01,  1.1904e+00, -1.2813e+00]],\n",
       "\n",
       "        [[-1.6285e+00, -1.6911e+00,  5.5387e-02, -1.6507e+00],\n",
       "         [ 2.1087e-01, -1.1325e+00,  1.2331e+00,  2.8895e-01],\n",
       "         [ 1.8064e+00, -1.1330e-01,  2.9672e-01,  1.5957e-01],\n",
       "         [ 2.4114e-01, -1.1229e+00,  9.7628e-01, -6.5015e-01]],\n",
       "\n",
       "        [[ 4.7679e-01,  5.6372e-01,  2.8561e-01,  1.0265e+00],\n",
       "         [-6.6995e-01, -1.2969e-01,  2.1860e+00,  1.8343e+00],\n",
       "         [-1.2044e+00,  4.7310e-01,  8.5648e-01,  8.2419e-02],\n",
       "         [-4.5638e-01, -1.3656e+00,  6.9233e-01,  1.0186e-01]],\n",
       "\n",
       "        [[ 1.0010e-01,  4.2466e-01,  8.6448e-01, -8.2313e-02],\n",
       "         [-8.7955e-01,  9.1755e-01,  9.4769e-02, -1.9924e+00],\n",
       "         [-3.3751e-01,  5.4379e-01, -2.0579e+00, -3.0400e-03],\n",
       "         [ 2.4735e-01,  3.9347e-01, -1.2182e+00,  1.8204e+00]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07920d2a-87e1-49ca-940a-3517dca5b303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2833, -0.0852, -0.6095, -0.1740],\n",
       "        [ 0.2109, -0.1133,  0.0554,  0.1596],\n",
       "        [-0.4564, -0.1297,  0.2856,  0.0824],\n",
       "        [ 0.1001,  0.3935,  0.0948, -0.0030]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reductions.abs_min( a, 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14ea012e-6362-4143-95c8-0cd906147515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1165430/1165430 records have matching contig in FASTA\n",
      "removing 1045783/1165430 records based on contig blacklist\n",
      "returned 119647/1165430 records\n"
     ]
    }
   ],
   "source": [
    "vcf_sub = boda.data.VcfDataset(test_vcf.vcf, fasta_dict.fasta, \n",
    "                                                 WINDOW_SIZE, RELATIVE_START, RELATIVE_END, step_size=STEP_SIZE,\n",
    "                                                 reverse_complements=REVERSE_COMPLEMENTS, use_contigs=['chr10', 'chr11'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
