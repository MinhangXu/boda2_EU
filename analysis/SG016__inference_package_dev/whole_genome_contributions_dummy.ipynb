{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "settled-arctic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "import shutil\n",
    "import random\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (random_split, DataLoader, TensorDataset, ConcatDataset)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "from Bio import motifs\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "import boda\n",
    "from boda.common import constants, utils\n",
    "\n",
    "boda_src = os.path.join( os.path.dirname( os.path.dirname( os.getcwd() ) ), 'src' )\n",
    "sys.path.insert(0, boda_src)\n",
    "\n",
    "from main import unpack_artifact, model_fn\n",
    "from pymeme import streme, parse_streme_output\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "from boda.generator.plot_tools import matrix_to_dms, ppm_to_IC, ppm_to_pwm, counts_to_ppm\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-shoot",
   "metadata": {},
   "source": [
    "### Batch example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "shared-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dna2tensor_approx(sequence_str, vocab_list=constants.STANDARD_NT):\n",
    "    seq_tensor = np.zeros((len(vocab_list), len(sequence_str)))\n",
    "    for letterIdx, letter in enumerate(sequence_str):\n",
    "        try:\n",
    "            seq_tensor[vocab_list.index(letter), letterIdx] = 1\n",
    "        except:\n",
    "            seq_tensor[:, letterIdx] = 0.25\n",
    "    seq_tensor = torch.Tensor(seq_tensor)\n",
    "    return seq_tensor\n",
    "\n",
    "def df_to_onehot_tensor(in_df, seq_column='nt_sequence'):\n",
    "    onehot_sequences = torch.stack([dna2tensor_approx(subsequence) \\\n",
    "                                for subsequence in tqdm(in_df[seq_column])])\n",
    "    return onehot_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fallen-isaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_01\n"
     ]
    }
   ],
   "source": [
    "chunk_idx = 1\n",
    "chunk_name = 'chunk_' + str(chunk_idx).zfill(2)\n",
    "print(chunk_name)\n",
    "chunk_path = 'df_chunks/' + chunk_name + '.txt'\n",
    "\n",
    "line_dict = {} \n",
    "with open(chunk_path, 'r') as f:\n",
    "    for line in f:\n",
    "        ID, sequence = line.lstrip('>::').rstrip('\\n').split('\\t')\n",
    "        line_dict[ID] = sequence.upper()\n",
    "temp_df = pd.DataFrame(line_dict.items(), columns=['ID', 'nt_sequence'])\n",
    "temp_df['seq_len'] = temp_df.apply(lambda x: len(x['nt_sequence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "infrared-prescription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861c84e743754d4eab6ad2f1b8fbde7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_batch = df_to_onehot_tensor(temp_df[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "speaking-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 200])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-arizona",
   "metadata": {},
   "source": [
    "# Function drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "visible-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mpra_predictor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 pred_idx=0,\n",
    "                 ini_in_len=200,\n",
    "                 model_in_len=600,\n",
    "                 cat_axis=-1,\n",
    "                 dual_pred=False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.pred_idx = pred_idx\n",
    "        self.ini_in_len = ini_in_len \n",
    "        self.model_in_len = model_in_len\n",
    "        self.cat_axis = cat_axis  \n",
    "        self.dual_pred = dual_pred\n",
    "        \n",
    "        try: self.model.eval()\n",
    "        except: pass\n",
    "        \n",
    "        self.register_flanks()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pieces = [self.left_flank.repeat(x.shape[0], 1, 1), x, self.right_flank.repeat(x.shape[0], 1, 1)]\n",
    "        in_tensor = torch.cat( pieces, axis=self.cat_axis)\n",
    "        if self.dual_pred:\n",
    "            dual_tensor = utils.reverse_complement_onehot(in_tensor)\n",
    "            out_tensor = self.model(in_tensor)[:, self.pred_idx] + self.model(dual_tensor)[:, self.pred_idx]\n",
    "            out_tensor = out_tensor / 2.0\n",
    "        else:\n",
    "            out_tensor = self.model(in_tensor)[:, self.pred_idx]\n",
    "        return out_tensor\n",
    "    \n",
    "    def register_flanks(self):\n",
    "        missing_len = self.model_in_len - self.ini_in_len\n",
    "        left_idx = - missing_len//2 + missing_len%2\n",
    "        right_idx = missing_len//2 + missing_len%2\n",
    "        left_flank = utils.dna2tensor(constants.MPRA_UPSTREAM[left_idx:]).unsqueeze(0)\n",
    "        right_flank = utils.dna2tensor(constants.MPRA_DOWNSTREAM[:right_idx]).unsqueeze(0)         \n",
    "        self.register_buffer('left_flank', left_flank)\n",
    "        self.register_buffer('right_flank', right_flank) \n",
    "        \n",
    "\n",
    "def isg_contributions(sequences,\n",
    "                      predictor,\n",
    "                      num_steps=50,\n",
    "                      num_samples=20,\n",
    "                      eval_batch_size=1024,\n",
    "                      theta_factor=15):\n",
    "    \n",
    "    batch_size = eval_batch_size // num_samples\n",
    "    temp_dataset = TensorDataset(sequences)\n",
    "    temp_dataloader = DataLoader(temp_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    all_salient_maps = []\n",
    "    all_gradients = []\n",
    "    for local_batch in tqdm(temp_dataloader):\n",
    "        target_thetas = (theta_factor * local_batch[0].cuda()).requires_grad_()\n",
    "        line_gradients = []\n",
    "        for i in range(0, num_steps + 1):\n",
    "            point_thetas = (i / num_steps * target_thetas)\n",
    "            point_distributions = F.softmax(point_thetas, dim=-2)\n",
    "\n",
    "            nucleotide_probs = Categorical(torch.transpose(point_distributions, -2, -1))\n",
    "            sampled_idxs = nucleotide_probs.sample((num_samples, ))\n",
    "            sampled_nucleotides_T = F.one_hot(sampled_idxs, num_classes=4)\n",
    "            sampled_nucleotides = torch.transpose(sampled_nucleotides_T, -2, -1)\n",
    "            distribution_repeater = point_distributions.repeat(num_samples, *[1 for i in range(3)])\n",
    "            sampled_nucleotides = sampled_nucleotides - distribution_repeater.detach() + distribution_repeater \n",
    "            samples = sampled_nucleotides.flatten(0,1)\n",
    "\n",
    "            preds = predictor(samples)\n",
    "            point_predictions = preds.unflatten(0, (num_samples, target_thetas.shape[0])).mean(dim=0)\n",
    "            point_gradients = torch.autograd.grad(point_predictions.sum(), inputs=point_thetas, retain_graph=True)[0]\n",
    "            line_gradients.append(point_gradients)\n",
    "            \n",
    "        gradients = torch.stack(line_gradients).mean(dim=0).detach()\n",
    "        all_salient_maps.append(gradients * target_thetas.detach())\n",
    "        all_gradients.append(gradients)\n",
    "    return theta_factor * torch.cat(all_gradients).cpu()\n",
    "    # return torch.cat(all_salient_maps).cpu(), theta_factor * torch.cat(all_gradients).cpu()\n",
    "\n",
    "\n",
    "def batch_to_contributions(onehot_sequences,\n",
    "                           model,\n",
    "                           model_output_len=3,\n",
    "                           seq_len = 200,\n",
    "                           eval_batch_size=1040):\n",
    "    \n",
    "    extended_contributions = []\n",
    "    for i in range(model_output_len):\n",
    "        predictor = mpra_predictor(model=model, pred_idx=i, ini_in_len=seq_len).cuda()\n",
    "        extended_contributions.append(isg_contributions(onehot_sequences, predictor, eval_batch_size=eval_batch_size))\n",
    "        \n",
    "    return torch.stack(extended_contributions)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-fisher",
   "metadata": {},
   "source": [
    "### Mock run        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "upset-geography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20211113_021200 in eval mode\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if os.path.isdir('./artifacts'):\n",
    "#     shutil.rmtree('./artifacts')\n",
    "# hpo_rec = 'gs://syrgoth/aip_ui_test/model_artifacts__20211113_021200__287348.tar.gz'\n",
    "# unpack_artifact(hpo_rec)\n",
    "\n",
    "model_dir = './artifacts'\n",
    "model = model_fn(model_dir)\n",
    "#model.cuda()\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "brave-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1b473bda0a412d83a62775f171cbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0812945958ab43e5923622f2f71304d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0591d0083b4348dcb9dab7320e56cfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_contributions = batch_to_contributions(onehot_sequences=example_batch,\n",
    "                                           model=model,\n",
    "                                           eval_batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "split-transparency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3563e-02,  1.1861e-02,  4.3333e-03,  ..., -1.7194e-02,\n",
       "           -2.7673e-02, -1.6030e-03],\n",
       "          [ 1.7821e-03, -1.6564e-02, -1.2404e-02,  ...,  1.0409e-02,\n",
       "            5.4094e-02, -3.4538e-02],\n",
       "          [-2.2099e-02,  7.3780e-04, -6.5452e-03,  ...,  2.1037e-02,\n",
       "           -4.0910e-03, -1.7237e-02],\n",
       "          [ 6.7543e-03,  3.9654e-03,  1.4616e-02,  ..., -1.4251e-02,\n",
       "           -2.2330e-02,  5.3378e-02]],\n",
       "\n",
       "         [[-2.6193e-02,  5.1062e-02,  3.4286e-02,  ..., -1.4842e-02,\n",
       "           -2.1771e-02, -6.2029e-03],\n",
       "          [-9.9690e-03, -2.9622e-03, -1.9139e-02,  ...,  1.1137e-02,\n",
       "            2.3121e-02, -2.2516e-02],\n",
       "          [-6.0820e-02, -3.1922e-02,  1.0546e-02,  ...,  9.2081e-03,\n",
       "           -2.8667e-04,  4.1596e-02],\n",
       "          [ 9.6982e-02, -1.6178e-02, -2.5692e-02,  ..., -5.5031e-03,\n",
       "           -1.0633e-03, -1.2877e-02]],\n",
       "\n",
       "         [[-1.2120e-02,  6.7470e-02,  4.3175e-02,  ..., -2.4565e-02,\n",
       "            2.6996e-05,  2.3800e-02],\n",
       "          [-5.3221e-03, -2.2707e-02, -2.7184e-02,  ...,  1.8659e-02,\n",
       "            3.3944e-03, -5.3709e-02],\n",
       "          [ 4.4536e-03, -2.5633e-02, -7.3288e-03,  ..., -7.5769e-03,\n",
       "            1.5330e-02,  4.6555e-03],\n",
       "          [ 1.2989e-02, -1.9129e-02, -8.6626e-03,  ...,  1.3483e-02,\n",
       "           -1.8752e-02,  2.5253e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.1157e-03,  8.2823e-03,  2.2672e-02,  ..., -9.7875e-02,\n",
       "           -9.0079e-02,  3.7036e-02],\n",
       "          [ 2.3357e-03,  8.3704e-03, -1.9546e-02,  ...,  4.6228e-02,\n",
       "            2.6845e-02, -5.1605e-02],\n",
       "          [-2.8604e-02, -1.1568e-02,  3.7254e-03,  ...,  2.8650e-02,\n",
       "            4.3228e-02,  1.0165e-02],\n",
       "          [ 2.3153e-02, -5.0851e-03, -6.8511e-03,  ...,  2.2997e-02,\n",
       "            2.0006e-02,  4.4041e-03]],\n",
       "\n",
       "         [[ 1.0651e-02,  8.5494e-03,  1.1392e-02,  ...,  7.2192e-03,\n",
       "           -9.5917e-03,  7.6819e-03],\n",
       "          [-3.1757e-03, -4.4246e-03, -2.3661e-02,  ...,  4.6933e-02,\n",
       "           -1.8073e-02, -3.5995e-02],\n",
       "          [-1.3646e-02,  4.9902e-04,  1.0387e-02,  ..., -4.8137e-02,\n",
       "            4.7380e-02, -1.9346e-02],\n",
       "          [ 6.1710e-03, -4.6238e-03,  1.8828e-03,  ..., -6.0147e-03,\n",
       "           -1.9715e-02,  4.7659e-02]],\n",
       "\n",
       "         [[ 9.6019e-03,  1.0839e-02,  3.3014e-02,  ...,  6.3187e-02,\n",
       "           -4.6035e-02,  3.0038e-03],\n",
       "          [-5.9777e-03, -4.5106e-03, -1.8797e-02,  ...,  4.0150e-03,\n",
       "           -7.3826e-03, -2.5363e-02],\n",
       "          [-2.2024e-02, -7.9817e-03, -5.8704e-03,  ..., -4.6711e-02,\n",
       "            7.9864e-02, -1.2292e-02],\n",
       "          [ 1.8400e-02,  1.6537e-03, -8.3466e-03,  ..., -2.0491e-02,\n",
       "           -2.6447e-02,  3.4652e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.4706e-02,  2.4835e-02,  7.6538e-03,  ..., -1.1658e-02,\n",
       "           -1.5602e-02, -1.8348e-02],\n",
       "          [-4.9390e-03, -1.5650e-02, -1.8232e-03,  ...,  1.2235e-02,\n",
       "            1.6600e-02, -3.8271e-02],\n",
       "          [-2.8613e-02,  9.4394e-03,  1.3994e-02,  ...,  2.5729e-02,\n",
       "            2.0021e-02, -2.0631e-02],\n",
       "          [-1.1538e-03, -1.8624e-02, -1.9824e-02,  ..., -2.6306e-02,\n",
       "           -2.1019e-02,  7.7250e-02]],\n",
       "\n",
       "         [[-9.4125e-03,  7.7742e-02,  3.7580e-02,  ..., -5.6394e-03,\n",
       "           -2.6672e-03,  1.7205e-03],\n",
       "          [-1.3509e-02, -2.9834e-02, -1.4466e-02,  ...,  1.7091e-02,\n",
       "           -2.8186e-03, -8.7630e-04],\n",
       "          [-7.3174e-02, -1.8393e-02,  2.5759e-02,  ..., -2.5836e-03,\n",
       "           -6.3892e-03, -5.7573e-03],\n",
       "          [ 9.6096e-02, -2.9515e-02, -4.8873e-02,  ..., -8.8676e-03,\n",
       "            1.1875e-02,  4.9132e-03]],\n",
       "\n",
       "         [[ 1.7799e-02,  1.0886e-01,  5.2476e-02,  ..., -1.6752e-02,\n",
       "           -3.5721e-03,  2.0833e-02],\n",
       "          [ 8.0408e-03, -5.1589e-02, -2.8316e-02,  ...,  1.4694e-02,\n",
       "           -4.2141e-03, -4.4028e-02],\n",
       "          [-3.1760e-02, -2.5032e-02, -3.8372e-03,  ...,  1.6743e-03,\n",
       "            2.3548e-03,  1.2997e-03],\n",
       "          [ 5.9195e-03, -3.2241e-02, -2.0322e-02,  ...,  3.8393e-04,\n",
       "            5.4314e-03,  2.1895e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.6157e-02,  1.6067e-02,  2.0106e-02,  ..., -2.5287e-02,\n",
       "           -2.0781e-02,  2.9859e-02],\n",
       "          [ 6.2543e-03, -2.5393e-02, -1.8579e-02,  ...,  2.2158e-02,\n",
       "            7.6205e-03, -6.6240e-02],\n",
       "          [-3.4789e-02,  1.2214e-02,  1.1927e-02,  ...,  2.2485e-03,\n",
       "            1.6382e-02,  1.9138e-03],\n",
       "          [ 2.3777e-03, -2.8890e-03, -1.3454e-02,  ...,  8.7957e-04,\n",
       "           -3.2213e-03,  3.4467e-02]],\n",
       "\n",
       "         [[ 3.2575e-02,  2.1626e-02,  2.0457e-02,  ..., -9.9871e-04,\n",
       "           -1.0490e-02,  9.8950e-03],\n",
       "          [-3.4849e-02, -1.0428e-02, -5.1560e-02,  ...,  2.3520e-02,\n",
       "           -3.4417e-03, -1.9851e-02],\n",
       "          [-4.0981e-03, -1.8520e-03,  3.3115e-02,  ..., -1.9555e-02,\n",
       "            7.5099e-03, -1.4442e-02],\n",
       "          [ 6.3715e-03, -9.3465e-03, -2.0119e-03,  ..., -2.9664e-03,\n",
       "            6.4213e-03,  2.4398e-02]],\n",
       "\n",
       "         [[ 2.0766e-02,  2.4759e-02,  1.2361e-02,  ...,  6.0831e-02,\n",
       "           -6.5566e-03, -9.9431e-03],\n",
       "          [ 4.6337e-03, -2.1857e-02, -9.8181e-03,  ...,  8.0915e-03,\n",
       "            1.3342e-02, -1.4605e-02],\n",
       "          [-2.5778e-02,  8.3817e-03,  9.2652e-03,  ..., -4.4144e-02,\n",
       "            2.3142e-02, -2.7907e-02],\n",
       "          [ 3.7904e-04, -1.1284e-02, -1.1808e-02,  ..., -2.4779e-02,\n",
       "           -2.9927e-02,  5.2455e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 6.1993e-02,  2.4765e-02,  1.2853e-02,  ...,  1.1371e-02,\n",
       "            3.0046e-03, -7.2370e-03],\n",
       "          [-1.8844e-02, -1.8297e-02, -8.8406e-03,  ...,  2.0751e-02,\n",
       "           -3.7882e-03, -9.4071e-03],\n",
       "          [-3.8104e-02,  8.5769e-03,  6.2755e-03,  ..., -2.8680e-02,\n",
       "            1.1755e-02, -2.1501e-02],\n",
       "          [-5.0455e-03, -1.5046e-02, -1.0288e-02,  ..., -3.4421e-03,\n",
       "           -1.0972e-02,  3.8146e-02]],\n",
       "\n",
       "         [[ 1.4531e-02,  4.9320e-02,  2.9925e-02,  ...,  2.0481e-03,\n",
       "            7.8240e-03, -1.0387e-02],\n",
       "          [-9.8956e-03, -1.8199e-02, -1.4256e-02,  ...,  1.4651e-02,\n",
       "           -4.8978e-03, -1.0868e-03],\n",
       "          [-4.1798e-02, -2.3265e-02,  1.6245e-02,  ..., -1.4062e-02,\n",
       "            1.2556e-03,  5.8038e-04],\n",
       "          [ 3.7163e-02, -7.8557e-03, -3.1914e-02,  ..., -2.6365e-03,\n",
       "           -4.1818e-03,  1.0894e-02]],\n",
       "\n",
       "         [[ 2.2325e-02,  1.0742e-01,  9.4496e-02,  ...,  3.6635e-02,\n",
       "           -6.4526e-03,  4.7788e-03],\n",
       "          [-1.7516e-02, -5.2272e-02, -4.1379e-02,  ..., -4.7803e-03,\n",
       "            2.8146e-03, -2.2592e-02],\n",
       "          [ 1.0915e-02, -1.8693e-02, -1.9891e-02,  ..., -1.7729e-02,\n",
       "           -1.0565e-02,  2.6641e-03],\n",
       "          [-1.5724e-02, -3.6452e-02, -3.3225e-02,  ..., -1.4126e-02,\n",
       "            1.4203e-02,  1.5149e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.1461e-02,  9.8110e-03,  3.4350e-02,  ...,  2.0639e-02,\n",
       "            2.7994e-07,  9.3717e-03],\n",
       "          [-8.2039e-03, -2.1262e-02, -2.1338e-02,  ..., -7.1889e-03,\n",
       "           -3.1554e-03, -3.1780e-02],\n",
       "          [-1.3974e-02,  2.0202e-02,  4.8656e-03,  ..., -1.8321e-03,\n",
       "           -3.5865e-04,  5.8430e-03],\n",
       "          [-9.2834e-03, -8.7510e-03, -1.7877e-02,  ..., -1.1618e-02,\n",
       "            3.5138e-03,  1.6565e-02]],\n",
       "\n",
       "         [[ 5.6641e-02, -9.6385e-04,  3.0563e-02,  ...,  2.1133e-02,\n",
       "            4.7778e-03,  1.0062e-02],\n",
       "          [-7.1727e-02, -1.7540e-03, -7.0627e-02,  ...,  2.9221e-02,\n",
       "            6.5384e-04, -3.6167e-02],\n",
       "          [ 7.0450e-03,  6.4318e-03,  3.6232e-02,  ..., -5.7714e-02,\n",
       "           -8.3619e-03, -7.9668e-03],\n",
       "          [ 8.0407e-03, -3.7140e-03,  3.8324e-03,  ...,  7.3605e-03,\n",
       "            2.9302e-03,  3.4071e-02]],\n",
       "\n",
       "         [[ 4.3468e-02,  3.0001e-02,  2.0285e-02,  ...,  3.8376e-02,\n",
       "            3.8596e-03,  1.4021e-02],\n",
       "          [-3.4639e-02, -1.6363e-02, -2.4140e-02,  ...,  2.6674e-03,\n",
       "           -1.1714e-02, -1.4948e-02],\n",
       "          [-1.3871e-02,  5.9342e-03,  1.0632e-02,  ..., -2.6194e-02,\n",
       "            1.6544e-02, -1.7401e-02],\n",
       "          [ 5.0423e-03, -1.9572e-02, -6.7769e-03,  ..., -1.4850e-02,\n",
       "           -8.6896e-03,  1.8327e-02]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-papua",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
