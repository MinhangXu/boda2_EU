{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b977fb2-039c-427f-b3a8-0fbb46267f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from functorch import combine_state_for_ensemble, vmap\n",
    "\n",
    "import boda\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from scipy.stats import pearsonr\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e20f1-ac21-4efa-a68a-7de042e9c92f",
   "metadata": {},
   "source": [
    "# Set helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3370e3-747a-476f-91c9-4dfdaaef59bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(artifact_path):\n",
    "    \n",
    "    USE_CUDA = torch.cuda.device_count() >= 1\n",
    "    if os.path.isdir('./artifacts'):\n",
    "        shutil.rmtree('./artifacts')\n",
    "\n",
    "    boda.common.utils.unpack_artifact(artifact_path)\n",
    "\n",
    "    model_dir = './artifacts'\n",
    "\n",
    "    my_model = boda.common.utils.model_fn(model_dir)\n",
    "    my_model.eval()\n",
    "    if USE_CUDA:\n",
    "        my_model.cuda()\n",
    "    \n",
    "    return my_model\n",
    "\n",
    "class ConsistentModelPool(nn.Module):\n",
    "    \"\"\"\n",
    "    Ensemble of consistent models.\n",
    "\n",
    "    This class creates an ensemble of consistent models from a list of model paths.\n",
    "    \n",
    "    Args:\n",
    "        path_list (list): List of paths to model artifacts.\n",
    "\n",
    "    Attributes:\n",
    "        fmodel (nn.Module): The ensemble forward model.\n",
    "        params (dict): Parameters shared across models.\n",
    "        buffers (dict): Buffers shared across models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 path_list\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialize the ConsistentModelPool with a list of model paths.\n",
    "\n",
    "        Args:\n",
    "            path_list (list): List of paths to model artifacts.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        models = [ load_model(model_path) for model_path in path_list ]\n",
    "        self.fmodel, self.params, self.buffers = combine_state_for_ensemble(models)\n",
    "            \n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Forward pass through the ensemble.\n",
    "\n",
    "        Args:\n",
    "            batch (torch.Tensor): Input data batch.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predictions from the ensemble.\n",
    "        \"\"\"\n",
    "        preds = vmap(self.fmodel, in_dims=(0, 0, None))(self.params, self.buffers, batch)\n",
    "        return preds.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197ca36-6463-47c7-a71f-6f0b2d0544cf",
   "metadata": {},
   "source": [
    "# Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a5a3c0-96e1-4371-bd44-368e7f6ec3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left flank shape: torch.Size([1, 4, 200])\n",
      "right flank shape: torch.Size([1, 4, 200])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FlankBuilder()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_flank = boda.common.utils.dna2tensor( \n",
    "    boda.common.constants.MPRA_UPSTREAM[-200:] \n",
    ").unsqueeze(0)\n",
    "print(f'left flank shape: {left_flank.shape}')\n",
    "\n",
    "right_flank= boda.common.utils.dna2tensor( \n",
    "    boda.common.constants.MPRA_DOWNSTREAM[:200] \n",
    ").unsqueeze(0)\n",
    "right_flank.shape\n",
    "print(f'right flank shape: {right_flank.shape}')\n",
    "\n",
    "flank_builder = boda.common.utils.FlankBuilder(\n",
    "    left_flank=left_flank,\n",
    "    right_flank=right_flank,\n",
    ")\n",
    "\n",
    "flank_builder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4af87c8-f05b-40ec-aa3d-54310b762dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_in = 'satmut_20230921.txt'\n",
    "\n",
    "with open(fn_in,'r') as f:\n",
    "    header = f.readline()\n",
    "    seq_data = {}\n",
    "    id_data  = {}\n",
    "    for line in f:\n",
    "        lsplit = line.rstrip().split('\\t')\n",
    "        chrom = lsplit[9]\n",
    "        ID    = lsplit[0]\n",
    "        seq = line.split()[-1]\n",
    "        seq = torch.cat([torch.zeros(4,200 - len(seq)), boda.common.utils.dna2tensor(seq)], axis=1)\n",
    "        try:\n",
    "            seq_data[chrom].append(seq)\n",
    "            id_data[chrom].append(ID)\n",
    "        except KeyError:\n",
    "            seq_data[chrom] = [seq]\n",
    "            id_data[chrom] = [ID]\n",
    "    \n",
    "    for key in seq_data.keys():\n",
    "        seq_data[key] = torch.stack( seq_data[key] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c09ca4-f810-4180-ba2e-e36c4fa639b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '3', '4', '5', '6', '7', '8', '9', 'X'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e94bd4f-1acc-4e8d-a20d-012bcdd8f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_1_val_10/model_artifacts__20230112_024037__325298.tar.gz...\n",
      "\\ [1 files][ 49.1 MiB/ 49.1 MiB]                                                \n",
      "Operation completed over 1 objects/49.1 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230112_024037 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_1_val_11/model_artifacts__20230112_003539__758935.tar.gz...\n",
      "\\ [1 files][ 49.8 MiB/ 49.8 MiB]                                                \n",
      "Operation completed over 1 objects/49.8 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230112_003539 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_1_val_2/model_artifacts__20230111_192235__715916.tar.gz...\n",
      "| [1 files][ 49.8 MiB/ 49.8 MiB]                                                \n",
      "Operation completed over 1 objects/49.8 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230111_192235 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_1_val_3/model_artifacts__20230111_190417__993143.tar.gz...\n",
      "| [1 files][ 49.2 MiB/ 49.2 MiB]                                                \n",
      "Operation completed over 1 objects/49.2 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230111_190417 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_1_val_4/model_artifacts__20230112_000934__941678.tar.gz...\n",
      "| [1 files][ 49.8 MiB/ 49.8 MiB]                                                \n",
      "Operation completed over 1 objects/49.8 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230112_000934 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_1_val_5/model_artifacts__20230112_003327__287605.tar.gz...\n",
      "| [1 files][ 49.4 MiB/ 49.4 MiB]                                                \n",
      "Operation completed over 1 objects/49.4 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230112_003327 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_1_val_6/model_artifacts__20230112_020038__431749.tar.gz...\n",
      "/ [1 files][ 51.0 MiB/ 51.0 MiB]                                                \n",
      "Operation completed over 1 objects/51.0 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230112_020038 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_1_val_7/model_artifacts__20230112_182326__436818.tar.gz...\n",
      "| [1 files][ 49.4 MiB/ 49.4 MiB]                                                \n",
      "Operation completed over 1 objects/49.4 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230112_182326 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_1_val_8/model_artifacts__20230112_014853__150994.tar.gz...\n",
      "\\ [1 files][ 51.3 MiB/ 51.3 MiB]                                                \n",
      "Operation completed over 1 objects/51.3 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230112_014853 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_1_val_9/model_artifacts__20230111_232551__863644.tar.gz...\n",
      "\\ [1 files][ 51.1 MiB/ 51.1 MiB]                                                \n",
      "Operation completed over 1 objects/51.1 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230111_232551 in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0047acb5144e658c2a4bdd6b446423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:696: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::max_pool1d. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at ../aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11146/2032529648.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprepped_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflank_builder\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprepped_seq\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                           \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprepped_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# Also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11146/2217263192.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPredictions\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/functorch/_src/vmap.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_in_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_batched_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         return _flat_vmap(\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_in_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         )\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/functorch/_src/vmap.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_saved_tensors_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/functorch/_src/vmap.py\u001b[0m in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mbatched_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_batched_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_in_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mbatched_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unwrap_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/functorch/_src/make_functional.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, params, buffers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             list(params) + list(buffers))\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateless_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;31m# Remove the loaded state on self.stateless_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/boda2/boda/model/contrib.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \"\"\"\n\u001b[0;32m-> 1136\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0moutput\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/boda2/boda/model/contrib.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad2\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool_4\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad3\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m         \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool_4\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad4\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/boda2/boda/model/basset.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \"\"\"\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_layer\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         )\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2451\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m     )\n\u001b[1;32m   2453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grab_str = 'gs://tewhey-public-data/crossval_models/models_230111/test_{}_*/model_artifacts*'\n",
    "\n",
    "for i in range(22):\n",
    "    chrom = str(i+1)\n",
    "    \n",
    "    if int(chrom) > 11:\n",
    "        model_chrom = 23 - int(chrom)\n",
    "    else:\n",
    "        model_chrom = chrom\n",
    "    \n",
    "    model_paths = !gsutil ls {grab_str.format(model_chrom)}\n",
    "    \n",
    "    my_model = ConsistentModelPool(model_paths)\n",
    "    \n",
    "    !rm model_artifacts*tar.gz\n",
    "    \n",
    "    seq_dataset = TensorDataset(seq_data[chrom])\n",
    "    seq_loader  = DataLoader(seq_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for j, batch in enumerate(tqdm.tqdm(seq_loader)):\n",
    "            prepped_seq = flank_builder( batch[0].cuda() )\n",
    "            predictions = my_model( prepped_seq ) + \\\n",
    "                          my_model( prepped_seq.flip(dims=[1,2]) ) # Also\n",
    "            predictions = predictions.div(2.)\n",
    "            results.append(predictions.detach().cpu())\n",
    "        \n",
    "    predictions = torch.cat(results, dim=0)\n",
    "    \n",
    "    outputs = pd.DataFrame(predictions.numpy(), columns=['K562','HepG2', 'SKNSH'])\n",
    "    outputs['ID'] = id_data[chrom]\n",
    "    \n",
    "    outputs.loc[:,['ID','K562','HepG2', 'SKNSH']] \\\n",
    "    .to_csv(f'satmut_20230921_preds_chr{chrom}.txt', sep='\\t', index=False, quoting=csv.QUOTE_NONE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d61d7376-1a8c-4302-be75-271ea064af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_str = 'gs://tewhey-public-data/crossval_models/models_230111/test_{}_*/model_artifacts*'\n",
    "\n",
    "model_list = !gsutil ls {grab_str.format(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbb8b950-b422-453c-a02a-8480ee09f53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://tewhey-public-data/crossval_models/models_230111/test_2_val_1/model_artifacts__20230112_041842__826676.tar.gz',\n",
       " 'gs://tewhey-public-data/crossval_models/models_230111/test_2_val_10/model_artifacts__20230112_031741__363749.tar.gz',\n",
       " 'gs://tewhey-public-data/crossval_models/models_230111/test_2_val_11/model_artifacts__20230112_002409__248129.tar.gz',\n",
       " 'gs://tewhey-public-data/crossval_models/models_230111/test_2_val_3/model_artifacts__20230112_173424__415672.tar.gz',\n",
       " 'gs://tewhey-public-data/crossval_models/models_230111/test_2_val_4/model_artifacts__20230112_014533__217034.tar.gz',\n",
       " 'gs://tewhey-public-data/crossval_models/models_230111/test_2_val_5/model_artifacts__20230112_003824__879872.tar.gz',\n",
       " 'gs://tewhey-public-data/crossval_models/models_230111/test_2_val_6/model_artifacts__20230111_233731__117900.tar.gz',\n",
       " 'gs://tewhey-public-data/crossval_models/models_230111/test_2_val_7/model_artifacts__20230112_023910__737605.tar.gz',\n",
       " 'gs://tewhey-public-data/crossval_models/models_230111/test_2_val_8/model_artifacts__20230112_004119__145637.tar.gz',\n",
       " 'gs://tewhey-public-data/crossval_models/models_230111/test_2_val_9/model_artifacts__20230112_005430__748782.tar.gz']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bcb0fca-1490-4671-bd71-2694aee300d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CommandException: One or more URLs matched no objects.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_paths = !gsutil ls {grab_str.format(chrom)}\n",
    "model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dc6dd9e-9e9d-4a54-bc66-eae34433e9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://tewhey-public-data/crossval_models/models_230111/test_18_*/model_artifacts*'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grab_str.format(chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ea89b99-6ccd-4f86-a104-45ba40b28010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_2_val_3/model_artifacts__20230112_173424__415672.tar.gz...\n",
      "| [1 files][ 49.1 MiB/ 49.1 MiB]                                                \n",
      "Operation completed over 1 objects/49.1 MiB.                                     \n",
      "archive unpacked in ./\n"
     ]
    }
   ],
   "source": [
    "test = boda.common.utils.unpack_artifact('gs://tewhey-public-data/crossval_models/models_230111/test_2_val_3/model_artifacts__20230112_173424__415672.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22508bdf-dac8-4f1b-931a-a1a2ddf4a434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tewhey-public-data/crossval_models/models_230111/test_2_val_3/model_artifacts__20230112_173424__415672.tar.gz...\n",
      "\\ [1 files][ 49.1 MiB/ 49.1 MiB]                                                \n",
      "Operation completed over 1 objects/49.1 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20230112_173424 in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "archive unpacked in ./\n"
     ]
    }
   ],
   "source": [
    "test = load_model('gs://tewhey-public-data/crossval_models/models_230111/test_2_val_3/model_artifacts__20230112_173424__415672.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0573b7-6448-469f-9844-c0ccc4619b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm.tqdm(seq_loader)):\n",
    "        prepped_seq = flank_builder( batch[0].cuda() )\n",
    "        predictions = my_model( prepped_seq ) + \\\n",
    "                      my_model( prepped_seq.flip(dims=[1,2]) ) # Also\n",
    "        predictions = predictions.div(2.)\n",
    "        results.append(predictions.detach().cpu())\n",
    "                \n",
    "predictions = torch.cat(results, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a75efcdd-8c73-4dea-b650-71a7294f583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([350768, 4, 200])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75f032b-7992-4261-8366-2d8af92f0a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347294"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ x.shape[1] == 200 for x in seq_tensor ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c89b91c-1e72-4f86-a27d-f0f632f48087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ x.shape[1] > 200 for x in seq_tensor ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
