{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "negative-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "from Bio import motifs\n",
    "\n",
    "import boda\n",
    "from boda.generator.parameters import StraightThroughParameters\n",
    "from boda.generator import FastSeqProp\n",
    "from boda.generator.plot_tools import matrix_to_dms, ppm_to_IC, ppm_to_pwm\n",
    "from boda.model.mpra_basset import MPRA_Basset\n",
    "from boda.common import constants, utils\n",
    "from boda.data import MPRA_DataModule\n",
    "\n",
    "boda_src = os.path.join( os.path.dirname( os.path.dirname( os.getcwd() ) ), 'src' )\n",
    "sys.path.insert(0, boda_src)\n",
    "\n",
    "from main import unpack_artifact, model_fn\n",
    "from pymeme import streme, parse_streme_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spiritual-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------- model -----------------------\n",
    "model = MPRA_Basset(extra_hidden_size = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beneficial-measure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://syrgoth/data/MPRA_UKBB_BODA_v2.txt...\n",
      "| [1 files][107.1 MiB/107.1 MiB]                                                \n",
      "Operation completed over 1 objects/107.1 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp gs://syrgoth/data/MPRA_UKBB_BODA_v2.txt ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thermal-twins",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "K562 | top cut value: 10.95, bottom cut value: -6.0\n",
      "HepG2 | top cut value: 9.99, bottom cut value: -5.26\n",
      "SKNSH | top cut value: 10.14, bottom cut value: -5.51\n",
      "\n",
      "Number of examples discarded from top: 0\n",
      "Number of examples discarded from bottom: 8\n",
      "\n",
      "Number of examples available: 358538\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Padding sequences...\n",
      "Tokenizing sequences...\n",
      "Creating train/val/test datasets...\n",
      "--------------------------------------------------\n",
      "\n",
      "Number of examples in train: 295827 (82.51%)\n",
      "Number of examples in val:   31453 (8.77%)\n",
      "Number of examples in test:  31258 (8.72%)\n",
      "\n",
      "Excluded from train: 0 (0.0)%\n",
      "--------------------------------------------------\n",
      "CPU times: user 1min 25s, sys: 4.47 s, total: 1min 30s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "datamodule = MPRA_DataModule(datafile_path='MPRA_UKBB_BODA_v2.txt',\n",
    "                             data_project=['BODA', 'UKBB'], #['BODA', 'UKBB'],\n",
    "#                              project_column='data_project',\n",
    "#                              sequence_column='nt_sequence',\n",
    "#                              activity_columns=['K562_mean', 'HepG2_mean', 'SKNSH_mean'],\n",
    "#                              exclude_chr_train=['synth'], #['17', '19', '21', 'X'],\n",
    "#                              val_chrs=['17', '19', '21', 'X'], #['17', '19', '21', 'X']\n",
    "#                              test_chrs=[''], #['7','13'],\n",
    "#                              chr_column='chr',\n",
    "#                              std_multiple_cut=6.0,\n",
    "#                              up_cutoff_move=4.0,\n",
    "#                              synth_chr='synth',\n",
    "#                              synth_val_pct=10,\n",
    "#                              synth_test_pct=10,\n",
    "#                              synth_seed=0,\n",
    "#                              batch_size=32,\n",
    "                             padded_seq_len=600 \n",
    "#                              num_workers=8,\n",
    "#                              normalize=False\n",
    "                            )\n",
    "\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prerequisite-survival",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\n",
      "  | Name            | Type       | Params | In sizes  | Out sizes\n",
      "-----------------------------------------------------------------------\n",
      "0 | criterion       | MSELoss    | 0      | ?         | ?        \n",
      "1 | last_activation | Tanh       | 0      | [1, 250]  | [1, 250] \n",
      "2 | basset_net      | Basset     | 4.9 M  | ?         | ?        \n",
      "3 | output_1        | Sequential | 250 K  | [1, 1000] | [1, 1]   \n",
      "4 | output_2        | Sequential | 250 K  | [1, 1000] | [1, 1]   \n",
      "5 | output_3        | Sequential | 250 K  | [1, 1000] | [1, 1]   \n",
      "-----------------------------------------------------------------------\n",
      "751 K     Trainable params\n",
      "4.9 M     Non-trainable params\n",
      "5.6 M     Total params\n",
      "22.411    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa272a160fea4f7eaf98d97a6c5427f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'Shannon_entropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-81df00dd882d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                      logger=logger, callbacks=[lr_monitor], precision=16)\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, on_epoch)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;31m# lightning module method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_epoch_end\u001b[0;34m(self, outputs)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_overridden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation_epoch_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'validation_epoch_end'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# capture logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/boda2/boda/model/mpra_basset.py\u001b[0m in \u001b[0;36mvalidation_epoch_end\u001b[0;34m(self, validation_step_outputs)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mtargets\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_step_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mpearsons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_pearson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearson_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mshannon_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshannon_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshannon_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mShannon_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mspecificity_pearson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecificity_mean_pearson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearson_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshannon_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshannon_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pearson'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_pearson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Shannon_entropy' is not defined"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics import functional\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "#-------------------- Train only last layer ------------------------\n",
    "model.basset_net.freeze()\n",
    "\n",
    "model.epochs = 5\n",
    "model.learning_rate = 0.05     #0.05\n",
    "model.weight_decay = 1e-6      #1e-6\n",
    "model.scheduler = True         #True\n",
    "datamodule.batch_size = 1024   #1024\n",
    "\n",
    "logger = TensorBoardLogger('model_logs', name='MPRAbasset_logs', log_graph=True)\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=model.epochs, progress_bar_refresh_rate=10,\n",
    "                     logger=logger, callbacks=[lr_monitor], precision=16)\n",
    "\n",
    "trainer.fit(model, datamodule)\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "current-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_path='MPRA_UKBB_BODA_v2.txt'\n",
    "project_column='data_project'\n",
    "data_project=['BODA', 'UKBB']\n",
    "sequence_column='nt_sequence'\n",
    "chr_column='chr'\n",
    "activity_columns=['K562_mean', 'HepG2_mean', 'SKNSH_mean']\n",
    "\n",
    "columns = [sequence_column, *activity_columns, chr_column, project_column]\n",
    "temp_df = utils.parse_file(file_path=datafile_path, columns=columns)\n",
    "temp_df = temp_df[temp_df[project_column].isin(data_project)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "atmospheric-conditioning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nt_sequence</th>\n",
       "      <th>K562_mean</th>\n",
       "      <th>HepG2_mean</th>\n",
       "      <th>SKNSH_mean</th>\n",
       "      <th>chr</th>\n",
       "      <th>data_project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAAAAAAAAAGTGAGTAACAAAAACAAC...</td>\n",
       "      <td>1.114658</td>\n",
       "      <td>0.785664</td>\n",
       "      <td>0.715749</td>\n",
       "      <td>12</td>\n",
       "      <td>UKBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAAAAAAAAAGTGAGTAACAAAAACAAC...</td>\n",
       "      <td>1.228857</td>\n",
       "      <td>0.677087</td>\n",
       "      <td>0.748533</td>\n",
       "      <td>12</td>\n",
       "      <td>UKBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAAAAAAAACAGAAAAGAAAAGAAACAT...</td>\n",
       "      <td>0.354881</td>\n",
       "      <td>0.381372</td>\n",
       "      <td>-0.435285</td>\n",
       "      <td>12</td>\n",
       "      <td>UKBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAAAAAAAACAGAAAAGAAAAGAAACAT...</td>\n",
       "      <td>0.360825</td>\n",
       "      <td>0.630168</td>\n",
       "      <td>-0.256892</td>\n",
       "      <td>12</td>\n",
       "      <td>UKBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAAAAAAAACTAGTCGGGCATGGTGGCG...</td>\n",
       "      <td>0.207887</td>\n",
       "      <td>0.416471</td>\n",
       "      <td>0.289111</td>\n",
       "      <td>20</td>\n",
       "      <td>UKBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358541</th>\n",
       "      <td>TTTTTTTTTTTTGAGACGGAGTCTCACTCTGTCGCCCAAGTTGGAG...</td>\n",
       "      <td>0.962659</td>\n",
       "      <td>0.737992</td>\n",
       "      <td>0.554276</td>\n",
       "      <td>5</td>\n",
       "      <td>BODA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358542</th>\n",
       "      <td>TTTTTTTTTTTTTTACCTTATTTTGACTCAATGTCTGTTTTATCTG...</td>\n",
       "      <td>1.731245</td>\n",
       "      <td>1.093225</td>\n",
       "      <td>0.869407</td>\n",
       "      <td>1</td>\n",
       "      <td>BODA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358543</th>\n",
       "      <td>TTTTTTTTTTTTTTGACAGAGTCTTGCTCTGTCACCCAGGTTGGAG...</td>\n",
       "      <td>-0.300288</td>\n",
       "      <td>-0.470305</td>\n",
       "      <td>-0.591421</td>\n",
       "      <td>4</td>\n",
       "      <td>BODA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358544</th>\n",
       "      <td>TTTTTTTTTTTTTTTGTATTTTTAGTAGAGACAGGGTTTCACCATG...</td>\n",
       "      <td>0.925107</td>\n",
       "      <td>0.901311</td>\n",
       "      <td>0.703593</td>\n",
       "      <td>17</td>\n",
       "      <td>BODA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358545</th>\n",
       "      <td>TTTTTTTTTTTTTTTTGAGATGGAGTTTCCCTCTTGTCACCCAGGC...</td>\n",
       "      <td>1.064113</td>\n",
       "      <td>0.099737</td>\n",
       "      <td>0.525217</td>\n",
       "      <td>2</td>\n",
       "      <td>BODA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358546 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              nt_sequence  K562_mean  \\\n",
       "0       AAAAAAAAAAAAAAAAAAAAAAAAAAAAGTGAGTAACAAAAACAAC...   1.114658   \n",
       "1       AAAAAAAAAAAAAAAAAAAAAAAAAAAAGTGAGTAACAAAAACAAC...   1.228857   \n",
       "2       AAAAAAAAAAAAAAAAAAAAAAAAAAACAGAAAAGAAAAGAAACAT...   0.354881   \n",
       "3       AAAAAAAAAAAAAAAAAAAAAAAAAAACAGAAAAGAAAAGAAACAT...   0.360825   \n",
       "4       AAAAAAAAAAAAAAAAAAAAAAAAAAACTAGTCGGGCATGGTGGCG...   0.207887   \n",
       "...                                                   ...        ...   \n",
       "358541  TTTTTTTTTTTTGAGACGGAGTCTCACTCTGTCGCCCAAGTTGGAG...   0.962659   \n",
       "358542  TTTTTTTTTTTTTTACCTTATTTTGACTCAATGTCTGTTTTATCTG...   1.731245   \n",
       "358543  TTTTTTTTTTTTTTGACAGAGTCTTGCTCTGTCACCCAGGTTGGAG...  -0.300288   \n",
       "358544  TTTTTTTTTTTTTTTGTATTTTTAGTAGAGACAGGGTTTCACCATG...   0.925107   \n",
       "358545  TTTTTTTTTTTTTTTTGAGATGGAGTTTCCCTCTTGTCACCCAGGC...   1.064113   \n",
       "\n",
       "        HepG2_mean  SKNSH_mean chr data_project  \n",
       "0         0.785664    0.715749  12         UKBB  \n",
       "1         0.677087    0.748533  12         UKBB  \n",
       "2         0.381372   -0.435285  12         UKBB  \n",
       "3         0.630168   -0.256892  12         UKBB  \n",
       "4         0.416471    0.289111  20         UKBB  \n",
       "...            ...         ...  ..          ...  \n",
       "358541    0.737992    0.554276   5         BODA  \n",
       "358542    1.093225    0.869407   1         BODA  \n",
       "358543   -0.470305   -0.591421   4         BODA  \n",
       "358544    0.901311    0.703593  17         BODA  \n",
       "358545    0.099737    0.525217   2         BODA  \n",
       "\n",
       "[358546 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "attractive-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['seq_len'] = temp_df.apply(lambda x: len(x['nt_sequence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "therapeutic-karen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nt_sequence</th>\n",
       "      <th>K562_mean</th>\n",
       "      <th>HepG2_mean</th>\n",
       "      <th>SKNSH_mean</th>\n",
       "      <th>chr</th>\n",
       "      <th>data_project</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nt_sequence, K562_mean, HepG2_mean, SKNSH_mean, chr, data_project, seq_len]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[temp_df['seq_len'] > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "arranged-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "pad_column_name = 'padded_seq'\n",
    "padded_seq_len=200 \n",
    "\n",
    "padding_fn = partial(row_pad_sequence,\n",
    "                                  in_column_name=sequence_column,\n",
    "                                  padded_seq_len=padded_seq_len\n",
    "                                  )\n",
    "\n",
    "temp_df[pad_column_name] = temp_df.apply(padding_fn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "controversial-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['padded_seq_len'] = temp_df.apply(lambda x: len(x[pad_column_name]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "waiting-texture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nt_sequence</th>\n",
       "      <th>K562_mean</th>\n",
       "      <th>HepG2_mean</th>\n",
       "      <th>SKNSH_mean</th>\n",
       "      <th>chr</th>\n",
       "      <th>data_project</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>padded_seq</th>\n",
       "      <th>padded_seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nt_sequence, K562_mean, HepG2_mean, SKNSH_mean, chr, data_project, seq_len, padded_seq, padded_seq_len]\n",
       "Index: []"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[temp_df['padded_seq_len'] < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "western-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_pad_sequence(row,\n",
    "                     in_column_name='nt_sequence',\n",
    "                     padded_seq_len=400,\n",
    "                     upStreamSeq=constants.MPRA_UPSTREAM,\n",
    "                     downStreamSeq=constants.MPRA_DOWNSTREAM):\n",
    "    sequence = row[in_column_name]\n",
    "    origSeqLen = len(sequence)\n",
    "    paddingLen = padded_seq_len - origSeqLen\n",
    "    assert paddingLen <= (len(upStreamSeq) + len(downStreamSeq)), 'Not enough padding available'\n",
    "    if paddingLen > 0:\n",
    "        if -paddingLen//2 + paddingLen%2 < 0:\n",
    "            upPad = upStreamSeq[-paddingLen//2 + paddingLen%2:]\n",
    "        else:\n",
    "            upPad = ''\n",
    "        downPad = downStreamSeq[:paddingLen//2 + paddingLen%2]\n",
    "        paddedSequence = upPad + sequence + downPad\n",
    "        assert len(paddedSequence) == padded_seq_len, 'Kiubo?'\n",
    "        return paddedSequence\n",
    "    else:\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "further-corporation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nt_sequence</th>\n",
       "      <th>K562_mean</th>\n",
       "      <th>HepG2_mean</th>\n",
       "      <th>SKNSH_mean</th>\n",
       "      <th>chr</th>\n",
       "      <th>data_project</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>padded_seq</th>\n",
       "      <th>padded_seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAGAAAGAAAAAAAGAAAGAAAGAAAGA...</td>\n",
       "      <td>0.062643</td>\n",
       "      <td>0.445604</td>\n",
       "      <td>2.195362</td>\n",
       "      <td>3</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>199</td>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAGAAAGAAAAAAAGAAAGAAAGAAAGA...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAGGATTTGAGCTAGAAAATGGGACCAT...</td>\n",
       "      <td>2.954926</td>\n",
       "      <td>3.041289</td>\n",
       "      <td>2.299703</td>\n",
       "      <td>1</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>199</td>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAGGATTTGAGCTAGAAAATGGGACCAT...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>AAAAAAAAAAAAAAAAAACTTCCCTCTAAATACACACATTAATAAT...</td>\n",
       "      <td>0.720907</td>\n",
       "      <td>0.459670</td>\n",
       "      <td>0.524583</td>\n",
       "      <td>13</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>199</td>\n",
       "      <td>AAAAAAAAAAAAAAAAAACTTCCCTCTAAATACACACATTAATAAT...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>AAAAAAAAAAAAAAAAAGCAAGAGAGATAAAATACATGGTTCTAAA...</td>\n",
       "      <td>0.716638</td>\n",
       "      <td>0.455792</td>\n",
       "      <td>0.456843</td>\n",
       "      <td>1</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>194</td>\n",
       "      <td>AAAAAAAAAAAAAAAAAGCAAGAGAGATAAAATACATGGTTCTAAA...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>AAAAAAAAAAAAAAAACAACAAAATAAAATTCCCAACATGCAGATA...</td>\n",
       "      <td>1.591423</td>\n",
       "      <td>1.276372</td>\n",
       "      <td>0.608198</td>\n",
       "      <td>3</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>199</td>\n",
       "      <td>AAAAAAAAAAAAAAAACAACAAAATAAAATTCCCAACATGCAGATA...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330198</th>\n",
       "      <td>TTTTTTTTTTTTTTTGAGACGGAGTCTCGCTCTGTCGCCCAGGCTG...</td>\n",
       "      <td>1.100679</td>\n",
       "      <td>0.595327</td>\n",
       "      <td>0.829593</td>\n",
       "      <td>7</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>199</td>\n",
       "      <td>TTTTTTTTTTTTTTTGAGACGGAGTCTCGCTCTGTCGCCCAGGCTG...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330225</th>\n",
       "      <td>TTTTTTTTTTTTTTTTGAGATGGAGTACCCATCTGTTGCTCAGGAT...</td>\n",
       "      <td>-0.247592</td>\n",
       "      <td>-0.208786</td>\n",
       "      <td>-0.188732</td>\n",
       "      <td>12</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>199</td>\n",
       "      <td>TTTTTTTTTTTTTTTTGAGATGGAGTACCCATCTGTTGCTCAGGAT...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330272</th>\n",
       "      <td>TTTTTTTTTTTTTTTTTTGACGGAGTCTTGCTCTGTTGCCAGGCTG...</td>\n",
       "      <td>-0.096071</td>\n",
       "      <td>-0.005683</td>\n",
       "      <td>0.351095</td>\n",
       "      <td>4</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>186</td>\n",
       "      <td>TTTTTTTTTTTTTTTTTTGACGGAGTCTTGCTCTGTTGCCAGGCTG...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330277</th>\n",
       "      <td>TTTTTTTTTTTTTTTTTTGAGACGGAGTCTCACTCTGTTGCCCAGG...</td>\n",
       "      <td>-0.815297</td>\n",
       "      <td>0.447955</td>\n",
       "      <td>0.212442</td>\n",
       "      <td>17</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>198</td>\n",
       "      <td>TTTTTTTTTTTTTTTTTTGAGACGGAGTCTCACTCTGTTGCCCAGG...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330283</th>\n",
       "      <td>TTTTTTTTTTTTTTTTTTGAGTCAGGGTCTTGCTCTGTCACTCAGG...</td>\n",
       "      <td>-0.667465</td>\n",
       "      <td>0.424493</td>\n",
       "      <td>0.542823</td>\n",
       "      <td>8</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>196</td>\n",
       "      <td>TTTTTTTTTTTTTTTTTTGAGTCAGGGTCTTGCTCTGTCACTCAGG...</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16688 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              nt_sequence  K562_mean  \\\n",
       "44      AAAAAAAAAAAAAAAAAAAAGAAAGAAAAAAAGAAAGAAAGAAAGA...   0.062643   \n",
       "51      AAAAAAAAAAAAAAAAAAAAGGATTTGAGCTAGAAAATGGGACCAT...   2.954926   \n",
       "75      AAAAAAAAAAAAAAAAAACTTCCCTCTAAATACACACATTAATAAT...   0.720907   \n",
       "103     AAAAAAAAAAAAAAAAAGCAAGAGAGATAAAATACATGGTTCTAAA...   0.716638   \n",
       "111     AAAAAAAAAAAAAAAACAACAAAATAAAATTCCCAACATGCAGATA...   1.591423   \n",
       "...                                                   ...        ...   \n",
       "330198  TTTTTTTTTTTTTTTGAGACGGAGTCTCGCTCTGTCGCCCAGGCTG...   1.100679   \n",
       "330225  TTTTTTTTTTTTTTTTGAGATGGAGTACCCATCTGTTGCTCAGGAT...  -0.247592   \n",
       "330272  TTTTTTTTTTTTTTTTTTGACGGAGTCTTGCTCTGTTGCCAGGCTG...  -0.096071   \n",
       "330277  TTTTTTTTTTTTTTTTTTGAGACGGAGTCTCACTCTGTTGCCCAGG...  -0.815297   \n",
       "330283  TTTTTTTTTTTTTTTTTTGAGTCAGGGTCTTGCTCTGTCACTCAGG...  -0.667465   \n",
       "\n",
       "        HepG2_mean  SKNSH_mean chr data_project  seq_len  \\\n",
       "44        0.445604    2.195362   3         UKBB      199   \n",
       "51        3.041289    2.299703   1         UKBB      199   \n",
       "75        0.459670    0.524583  13         UKBB      199   \n",
       "103       0.455792    0.456843   1         UKBB      194   \n",
       "111       1.276372    0.608198   3         UKBB      199   \n",
       "...            ...         ...  ..          ...      ...   \n",
       "330198    0.595327    0.829593   7         UKBB      199   \n",
       "330225   -0.208786   -0.188732  12         UKBB      199   \n",
       "330272   -0.005683    0.351095   4         UKBB      186   \n",
       "330277    0.447955    0.212442  17         UKBB      198   \n",
       "330283    0.424493    0.542823   8         UKBB      196   \n",
       "\n",
       "                                               padded_seq  padded_seq_len  \n",
       "44      AAAAAAAAAAAAAAAAAAAAGAAAGAAAAAAAGAAAGAAAGAAAGA...             400  \n",
       "51      AAAAAAAAAAAAAAAAAAAAGGATTTGAGCTAGAAAATGGGACCAT...             400  \n",
       "75      AAAAAAAAAAAAAAAAAACTTCCCTCTAAATACACACATTAATAAT...             400  \n",
       "103     AAAAAAAAAAAAAAAAAGCAAGAGAGATAAAATACATGGTTCTAAA...             400  \n",
       "111     AAAAAAAAAAAAAAAACAACAAAATAAAATTCCCAACATGCAGATA...             400  \n",
       "...                                                   ...             ...  \n",
       "330198  TTTTTTTTTTTTTTTGAGACGGAGTCTCGCTCTGTCGCCCAGGCTG...             400  \n",
       "330225  TTTTTTTTTTTTTTTTGAGATGGAGTACCCATCTGTTGCTCAGGAT...             400  \n",
       "330272  TTTTTTTTTTTTTTTTTTGACGGAGTCTTGCTCTGTTGCCAGGCTG...             400  \n",
       "330277  TTTTTTTTTTTTTTTTTTGAGACGGAGTCTCACTCTGTTGCCCAGG...             400  \n",
       "330283  TTTTTTTTTTTTTTTTTTGAGTCAGGGTCTTGCTCTGTCACTCAGG...             400  \n",
       "\n",
       "[16688 rows x 9 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[temp_df['seq_len'] < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "opposite-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq_len=200\n",
    "upStreamSeq=constants.MPRA_UPSTREAM\n",
    "downStreamSeq=constants.MPRA_DOWNSTREAM\n",
    "    \n",
    "sequence = temp_df.iloc[44]['nt_sequence']\n",
    "\n",
    "origSeqLen = len(sequence)\n",
    "paddingLen = padded_seq_len - origSeqLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "affected-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "if paddingLen > 0:\n",
    "    if -paddingLen//2 + paddingLen%2 < 0:\n",
    "        upPad = upStreamSeq[-paddingLen//2 + paddingLen%2:]\n",
    "    else:\n",
    "        upPad = ''\n",
    "    downPad = downStreamSeq[:paddingLen//2 + paddingLen%2]\n",
    "    paddedSequence = upPad + sequence + downPad\n",
    "    assert len(paddedSequence) == padded_seq_len, 'Kiubo?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "emotional-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paddedSequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "roman-composer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACGAAAATGTTGGATGCTCATACTCGTCCTTTTTCAATATTATTGAAGCATTTATCAGGGTTACTAGTACGTCTCTCAAGGATAAGTAAGTAATATTAAGGTACGGGAGGTATTGGACAGGCCGCAATAAAATATCTTTATTTTCATTACATCTGTGTGTTGGTTTTTTGTGTGAATCGATAGTACTAACATACGCTCTCCATCAAAACAAAACGAAACAAAACAAACTAGCAAAATAGGCTGTCCCCAGTGCAAGTGCAGGTGCCAGAACATTTCTCTGGCCTAACTGGCCGCTTGACG'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upPad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bearing-scheme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddingLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "above-child",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-paddingLen//2 + paddingLen%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "crucial-terrace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ACGAAAATGTTGGATGCTCATACTCGTCCTTTTTCAATATTATTGAAGCATTTATCAGGGTTACTAGTACGTCTCTCAAGGATAAGTAAGTAATATTAAGGTACGGGAGGTATTGGACAGGCCGCAATAAAATATCTTTATTTTCATTACATCTGTGTGTTGGTTTTTTGTGTGAATCGATAGTACTAACATACGCTCTCCATCAAAACAAAACGAAACAAAACAAACTAGCAAAATAGGCTGTCCCCAGTGCAAGTGCAGGTGCCAGAACATTTCTCTGGCCTAACTGGCCGCTTGACG',)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upStreamSeq[-paddingLen//2 + paddingLen%2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "surface-combining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ACGAAAATGTTGGATGCTCATACTCGTCCTTTTTCAATATTATTGAAGCATTTATCAGGGTTACTAGTACGTCTCTCAAGGATAAGTAAGTAATATTAAGGTACGGGAGGTATTGGACAGGCCGCAATAAAATATCTTTATTTTCATTACATCTGTGTGTTGGTTTTTTGTGTGAATCGATAGTACTAACATACGCTCTCCATCAAAACAAAACGAAACAAAACAAACTAGCAAAATAGGCTGTCCCCAGTGCAAGTGCAGGTGCCAGAACATTTCTCTGGCCTAACTGGCCGCTTGACG',)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upStreamSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "quality-aurora",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CACTGCGGCTCCTGCGATCTAACTGGCCGGTACCTGAGCTCGCTAGCCTCGAGGATATCAAGATCTGGCCTCGGCGGCCAAGCTTAGACACTAGAGGGTATATAATGGAAGCTCGACTTCCAGCTTGGCAATCCGGTACTGTTGGTAAAGCCACCATGGTGAGCAAGGGCGAGGAGCTGTTCACCGGGGTGGTGCCCATCCTGGTCGAGCTGGACGGCGACGTAAACGGCCACAAGTTCAGCGTGTCCGGCGAGGGCGAGGGCGATGCCACCTACGGCAAGCTGACCCTGAAGTTCATCT'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downStreamSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cordless-doubt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACGAAAATGTTGGATGCTCATACTCGTCCTTTTTCAATATTATTGAAGCATTTATCAGGGTTACTAGTACGTCTCTCAAGGATAAGTAAGTAATATTAAGGTACGGGAGGTATTGGACAGGCCGCAATAAAATATCTTTATTTTCATTACATCTGTGTGTTGGTTTTTTGTGTGAATCGATAGTACTAACATACGCTCTCCATCAAAACAAAACGAAACAAAACAAACTAGCAAAATAGGCTGTCCCCAGTGCAAGTGCAGGTGCCAGAACATTTCTCTGGCCTAACTGGCCGCTTGACG'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constants.MPRA_UPSTREAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "recorded-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "upStreamSeq=constants.MPRA_UPSTREAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bigger-residence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACGAAAATGTTGGATGCTCATACTCGTCCTTTTTCAATATTATTGAAGCATTTATCAGGGTTACTAGTACGTCTCTCAAGGATAAGTAAGTAATATTAAGGTACGGGAGGTATTGGACAGGCCGCAATAAAATATCTTTATTTTCATTACATCTGTGTGTTGGTTTTTTGTGTGAATCGATAGTACTAACATACGCTCTCCATCAAAACAAAACGAAACAAAACAAACTAGCAAAATAGGCTGTCCCCAGTGCAAGTGCAGGTGCCAGAACATTTCTCTGGCCTAACTGGCCGCTTGACG'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upStreamSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-shopping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
