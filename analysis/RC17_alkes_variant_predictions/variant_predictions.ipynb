{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "derived-angle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "import shutil\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import tempfile\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (random_split, DataLoader, TensorDataset, ConcatDataset)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "from Bio import motifs\n",
    "\n",
    "from google.cloud import storage\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "import boda\n",
    "from boda.generator.parameters import StraightThroughParameters\n",
    "from boda.generator import FastSeqProp\n",
    "from boda.generator.plot_tools import matrix_to_dms, ppm_to_IC, ppm_to_pwm\n",
    "from boda.model.mpra_basset import MPRA_Basset\n",
    "from boda.common import constants, utils\n",
    "\n",
    "boda_src = os.path.join( os.path.dirname( os.path.dirname( os.getcwd() ) ), 'src' )\n",
    "sys.path.insert(0, boda_src)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "from main import unpack_artifact, model_fn\n",
    "from pymeme import streme, parse_streme_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "changed-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fixed-length sequences\n",
    "def df_to_onehot_tensor(in_df, seq_column='sequence'):\n",
    "    onehot_sequences = torch.stack([utils.dna2tensor(subsequence) \\\n",
    "                                for subsequence in tqdm(in_df[seq_column])])\n",
    "    return onehot_sequences\n",
    "\n",
    "#for variable-length sequences\n",
    "def get_onehots(in_df, seq_column='nt_sequence', extra_str=''):\n",
    "    padding_fn = partial(utils.row_pad_sequence,\n",
    "                            in_column_name=seq_column,\n",
    "                            padded_seq_len=600)    \n",
    "    print('Padding sequences' + extra_str)\n",
    "    sequence_list = list(in_df.progress_apply(padding_fn, axis=1))     \n",
    "    print('Tokenizing sequences' + extra_str)\n",
    "    onehot_sequences = torch.stack([utils.dna2tensor(subsequence) for subsequence in tqdm(sequence_list)])\n",
    "    return onehot_sequences\n",
    "\n",
    "def get_predictions(onehot_sequences, model, eval_batch_size = 128, num_workers=2, extra_str=''):\n",
    "    temp_dataset = TensorDataset(onehot_sequences)\n",
    "    temp_dataloader = DataLoader(temp_dataset, batch_size=eval_batch_size, shuffle=False, num_workers=num_workers)\n",
    "    print('Getting predictions' + extra_str)  \n",
    "    preds = []\n",
    "    for local_batch in tqdm(temp_dataloader):\n",
    "        preds.append(model(local_batch[0].cuda()).cpu().detach().numpy())       \n",
    "    preds_array = np.concatenate(preds, axis=0)  \n",
    "    return preds_array\n",
    "\n",
    "def entropy(X):\n",
    "    p_c = F.softmax(torch.tensor(X, dtype=torch.float32), dim=1).numpy()\n",
    "    return np.sum(- p_c * np.log(p_c), axis=1)\n",
    "\n",
    "def dna2tensor_approx(sequence_str, vocab_list=constants.STANDARD_NT):\n",
    "    seq_tensor = np.zeros((len(vocab_list), len(sequence_str)))\n",
    "    for letterIdx, letter in enumerate(sequence_str):\n",
    "        try:\n",
    "            seq_tensor[vocab_list.index(letter), letterIdx] = 1\n",
    "        except:\n",
    "            seq_tensor[:, letterIdx] = 0.25\n",
    "    seq_tensor = torch.Tensor(seq_tensor)\n",
    "    return seq_tensor\n",
    "\n",
    "def frame_print(string, marker='*', left_space=25):\n",
    "    left_spacer = left_space * ' '\n",
    "    string = marker + ' ' + string.upper() + ' ' + marker\n",
    "    n = len(string)\n",
    "    print('', flush=True)\n",
    "    print('', flush=True)\n",
    "    print(left_spacer + n * marker, flush=True)\n",
    "    print(left_spacer + string, flush=True)\n",
    "    print(left_spacer + n * marker, flush=True)\n",
    "    print('', flush=True)\n",
    "    print('', flush=True)\n",
    "    \n",
    "def decor_print(string):\n",
    "    decor = 15*'-'\n",
    "    print('', flush=True)\n",
    "    print(decor + ' ' + string + ' ' + decor, flush=True)\n",
    "    print('', flush=True)\n",
    "    \n",
    "def over_max_bent(x, bias_cell=0, bending_factor=1.0):\n",
    "    x = x - bending_factor * (torch.exp(-x) - 1)\n",
    "    target = x[...,bias_cell]\n",
    "    non_target_max = x[...,[ i for i in range(x.shape[-1]) if i != bias_cell]].max(-1).values\n",
    "    return target - non_target_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chubby-concentrate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "archive unpacked in ./\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20211113_021200 in eval mode\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('./artifacts'):\n",
    "    shutil.rmtree('./artifacts')\n",
    "hpo_rec = 'gs://syrgoth/aip_ui_test/model_artifacts__20211113_021200__287348.tar.gz'\n",
    "unpack_artifact(hpo_rec)\n",
    "\n",
    "model_dir = './artifacts'\n",
    "model = model_fn(model_dir)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advisory-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_flank = utils.dna2tensor(constants.MPRA_UPSTREAM[-200:]).unsqueeze(0)\n",
    "right_flank = utils.dna2tensor(constants.MPRA_DOWNSTREAM[:200] ).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "israeli-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_blob_to_prediction(blob, model, left_flank, right_flank, eval_batch_size=512, pre_batch_size=50000, num_workers=2):\n",
    "    blob = blob.download_as_string()\n",
    "    blob = blob.decode('utf-8')\n",
    "    blob = StringIO(blob)  \n",
    "    lines = csv.reader(blob)\n",
    "    fasta_dict = {}\n",
    "    for line in lines:\n",
    "        line_str = str(line[0])\n",
    "        if line_str[0] == '>':\n",
    "            my_id = line_str.lstrip('>')\n",
    "            fasta_dict[my_id] = ''\n",
    "        else:\n",
    "            fasta_dict[my_id] += line_str.upper()\n",
    "    temp_df = pd.DataFrame(fasta_dict.items(), columns=['ID', 'nt_sequence'])\n",
    "    #temp_df['seq_len'] = temp_df.apply(lambda x: len(x['nt_sequence']), axis=1)\n",
    "    preds = []\n",
    "    df_len = len(temp_df)\n",
    "    print(f'Getting {df_len:,} predictions', flush=True) \n",
    "    for batch_start in tqdm((range(0, df_len, pre_batch_size))):\n",
    "        batch_end = batch_start + pre_batch_size\n",
    "        sub_temp_df = temp_df[batch_start : batch_end]\n",
    "        onehot_sequences = torch.stack([dna2tensor_approx(subsequence) \\\n",
    "                                        for subsequence in sub_temp_df['nt_sequence']])\n",
    "        pieces = [left_flank.repeat(onehot_sequences.shape[0], 1, 1), \\\n",
    "                onehot_sequences, \\\n",
    "                right_flank.repeat(onehot_sequences.shape[0], 1, 1)]\n",
    "        input_tensor = torch.cat(pieces, axis=-1)\n",
    "        temp_dataset = TensorDataset(input_tensor)\n",
    "        temp_dataloader = DataLoader(temp_dataset, batch_size=eval_batch_size, shuffle=False, num_workers=num_workers)\n",
    "        for local_batch in temp_dataloader:\n",
    "            preds.append(model(local_batch[0].cuda()).cpu().detach().numpy())        \n",
    "    preds_array = np.concatenate(preds, axis=0)\n",
    "    temp_df[['K562_pred', 'HepG2_pred', 'SKNSH_pred']] = preds_array    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "revolutionary-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Parsing cisX_tall_mel_ase_variants_200.fa ---------------\n",
      "\n",
      "Getting 352 predictions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dce121f634a4a56a6ca7e77b715c9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in gs://syrgoth/data/cosmic/predictions/cisX_tall_mel_ase_variants_200_pred.txt\n",
      "\n",
      "\n",
      "--------------- Parsing hbe1_mpra_sat_mut.fa ---------------\n",
      "\n",
      "Getting 2,478 predictions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c11c14ee16249d19523cdfcdd513daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in gs://syrgoth/data/cosmic/predictions/hbe1_mpra_sat_mut_pred.txt\n",
      "\n",
      "CPU times: user 768 ms, sys: 239 ms, total: 1.01 s\n",
      "Wall time: 5.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eval_batch_size = 512\n",
    "fata_names = ['cisX_tall_mel_ase_variants_200.fa', 'hbe1_mpra_sat_mut.fa']\n",
    "# rootdir = 'data/alkes/fastas/'\n",
    "# targetdir = 'gs://syrgoth/data/alkes/predictions_v1'\n",
    "rootdir = 'data/cosmic/fastas/'\n",
    "targetdir = 'gs://syrgoth/data/cosmic/predictions'\n",
    "\n",
    "bucket = storage.Client().get_bucket('syrgoth')\n",
    "for blob in bucket.list_blobs(prefix=rootdir):\n",
    "    filepath = blob.name\n",
    "    if filepath.endswith('.fa'): \n",
    "        base_name = os.path.basename(blob.name)\n",
    "        if base_name in fata_names:\n",
    "            out_file_name = base_name.rstrip('.fa') + '_pred.txt'\n",
    "            cloud_target = os.path.join(targetdir, out_file_name)\n",
    "\n",
    "            decor_print(f'Parsing {base_name}')\n",
    "            pred_df = fasta_blob_to_prediction(blob=blob,\n",
    "                                             model=model,\n",
    "                                             left_flank=left_flank,\n",
    "                                             right_flank=right_flank,\n",
    "                                             eval_batch_size=512)\n",
    "            with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                temp_loc = os.path.join(tmpdir, base_name)  \n",
    "                pred_df.to_csv(temp_loc, index=None, sep='\\t', float_format='%.15f')                \n",
    "                subprocess.check_call(\n",
    "                    ['gsutil', 'cp', temp_loc, cloud_target]\n",
    "                )\n",
    "                print('Predictions saved in ' + cloud_target, flush=True)\n",
    "                print('', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
