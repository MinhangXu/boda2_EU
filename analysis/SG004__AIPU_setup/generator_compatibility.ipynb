{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "retained-rings",
   "metadata": {},
   "source": [
    "!pip install imageio\n",
    "!pip install imageio-ffmpeg\n",
    "!pip install dmslogo\n",
    "!pip install palettable\n",
    "!pip install array_to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "future-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import boda\n",
    "\n",
    "boda_src = os.path.join( os.path.dirname( os.path.dirname( os.getcwd() ) ), 'src' )\n",
    "sys.path.insert(0, boda_src)\n",
    "\n",
    "from main import unpack_artifact, model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atmospheric-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-beverage",
   "metadata": {},
   "source": [
    "## Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lyric-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_hold = boda.common.utils.dna2tensor( (boda.common.constants.MPRA_UPSTREAM)[-200:] ).repeat(bsz,1,1)\n",
    "right_hold= boda.common.utils.dna2tensor( (boda.common.constants.MPRA_UPSTREAM)[:200] ).repeat(bsz,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "delayed-moore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recorded-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_params = boda.generator.GumbelSoftmaxParameters(\n",
    "    nn.Parameter(torch.randn([bsz,4,200])), \n",
    "    left_flank=left_hold, \n",
    "    right_flank=right_hold,\n",
    "    n_samples=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contemporary-contents",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 4, 600])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_params().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-death",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surprised-month",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20210515_230601\n"
     ]
    }
   ],
   "source": [
    "unpack_artifact('gs://syrgoth/aip_ui_test/model_artifacts__20210515_230601__116249.tar.gz')\n",
    "model_dir = './artifacts'\n",
    "\n",
    "my_model = model_fn(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-discipline",
   "metadata": {},
   "source": [
    "## Test model + parameters combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "superior-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBridge(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, hook):\n",
    "        probs     = self.model(hook).softmax(dim=1)\n",
    "        log_probs = probs.log()\n",
    "        return (probs*log_probs).sum(dim=1).mul(-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "super-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_fn = SEBridge(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_fn(my_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-guitar",
   "metadata": {},
   "source": [
    "## Test generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "animal-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sampler = boda.generator.NUTS3( my_params, energy_fn, max_tree_depth=6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accessible-killer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669.2568943500519\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "my_samples = my_sampler.collect_samples(1e-1,10)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-showcase",
   "metadata": {},
   "source": [
    "## Test cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pointed-gardening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEBridge(\n",
       "  (model): BassetVL(\n",
       "    (pad1): ConstantPad1d(padding=[9, 9], value=0.0)\n",
       "    (conv1): Conv1dNorm(\n",
       "      (conv): Conv1d(4, 300, kernel_size=(19,), stride=(1,))\n",
       "      (bn_layer): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pad2): ConstantPad1d(padding=[5, 5], value=0.0)\n",
       "    (conv2): Conv1dNorm(\n",
       "      (conv): Conv1d(300, 200, kernel_size=(11,), stride=(1,))\n",
       "      (bn_layer): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pad3): ConstantPad1d(padding=[3, 3], value=0.0)\n",
       "    (conv3): Conv1dNorm(\n",
       "      (conv): Conv1d(200, 200, kernel_size=(7,), stride=(1,))\n",
       "      (bn_layer): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pad4): ConstantPad1d(padding=(1, 1), value=0.0)\n",
       "    (maxpool_3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (maxpool_4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (linear1): LinearNorm(\n",
       "      (linear): Linear(in_features=2600, out_features=1000, bias=True)\n",
       "      (bn_layer): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (linear2): LinearNorm(\n",
       "      (linear): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "      (bn_layer): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (linear3): LinearNorm(\n",
       "      (linear): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "      (bn_layer): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (output): Linear(in_features=1000, out_features=3, bias=True)\n",
       "    (nonlin): ReLU()\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (criterion): MSELoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_params.cuda()\n",
    "energy_fn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "running-hurricane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0973, 1.0924, 1.0948, 1.0947, 1.0959, 1.0906, 1.0771, 1.0517, 1.0978,\n",
       "        1.0881, 1.0965, 1.0974, 1.0977, 1.0963, 1.0958, 1.0811, 1.0647, 1.0937,\n",
       "        1.0977, 1.0744, 1.0772, 1.0971, 1.0983, 1.0973, 1.0970, 1.0790, 1.0937,\n",
       "        1.0766, 1.0877, 0.9917, 1.0934, 1.0903, 1.0892, 1.0717, 1.0660, 1.0982,\n",
       "        1.0960, 1.0864, 1.0954, 1.0970], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_fn(my_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amber-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sampler = boda.generator.NUTS3( my_params, energy_fn, max_tree_depth=6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ongoing-verse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.746002435684204\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "my_samples = my_sampler.collect_samples(1e-1,10)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "federal-chapel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -6.8437,  17.8763,  -0.1315,  ..., -18.5676, -28.9050,  -4.3739],\n",
       "         [-23.0793,  17.8637, -17.6396,  ...,   9.6393, -38.7782,  -8.9497],\n",
       "         [  5.9327,  18.5760,  -3.2536,  ...,  24.2850,  -8.2704, -11.5782],\n",
       "         [-19.6584,  23.1742,  23.3611,  ...,  15.4485,   4.6120,  19.6974]],\n",
       "\n",
       "        [[  8.4275,  -3.4474,   1.0758,  ...,  -7.1960,   2.7149,  -3.7693],\n",
       "         [  6.4695,  40.1236,   5.8912,  ...,  16.8275,   2.4700,  14.5646],\n",
       "         [-14.4251,   1.4949,  11.0203,  ...,  25.2833,  -1.3034,   6.9184],\n",
       "         [ -9.5555,  11.5167,  -6.8069,  ...,   7.8747, -13.1826, -37.1442]],\n",
       "\n",
       "        [[ -1.8678,   6.0356,  10.5502,  ...,  14.9514, -11.8969,  -9.4892],\n",
       "         [ -0.9737, -15.3925,  19.8969,  ...,  -6.5278,  -7.2056,  -6.5082],\n",
       "         [ -0.1698, -30.8604, -25.1898,  ..., -21.0621,  32.6659,  13.3362],\n",
       "         [ -1.3777,  26.0208,   8.9887,  ...,   9.6813, -14.7003,  -0.6798]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-18.0933,  12.2198,  42.7688,  ...,   5.2563, -11.7524,   7.6257],\n",
       "         [ 30.0616, -11.1595, -19.3070,  ...,  32.0032,  -8.7284,  32.7270],\n",
       "         [ -3.8205,  20.8001, -24.8854,  ...,  15.3603,  26.0809,   8.5835],\n",
       "         [ -7.6196,   9.8258,  10.9682,  ...,  15.2672,   3.1100,   6.2146]],\n",
       "\n",
       "        [[ 13.2431,  17.2226, -19.3571,  ...,  12.0564,  -2.5008,  13.7489],\n",
       "         [ 33.9391,  -0.2634,  -0.2723,  ...,  -7.8115,   0.7763,   7.4122],\n",
       "         [  2.5195,  22.4242, -10.2092,  ..., -13.8728,  15.6866,  -1.3123],\n",
       "         [ 12.1175,   6.6403,   2.7009,  ...,  -2.8300,   1.4149,   6.4775]],\n",
       "\n",
       "        [[-28.6437,  -6.4618,  28.9457,  ...,  15.9402,  15.8438,  17.2509],\n",
       "         [ -2.2662,  -8.8849,  11.7240,  ...,  14.9892, -20.6926, -26.5059],\n",
       "         [ 11.3174,  21.1899, -19.1531,  ...,  -1.6335,  16.5146,   2.4732],\n",
       "         [ 12.1887,  19.1779,   2.4598,  ...,  -5.4619, -17.4285,   4.9016]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_samples[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "charitable-handbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0482, 1.0931, 1.0970, 1.0960, 1.0799, 1.0967, 1.0891, 1.0861, 1.0887,\n",
       "        1.0949, 1.0941, 1.0596, 1.0956, 1.0758, 1.0961, 1.0970, 1.0044, 1.0985,\n",
       "        1.0971, 1.0893, 1.0800, 1.0978, 1.0978, 1.0907, 1.0596, 1.0308, 1.0981,\n",
       "        1.0979, 1.0983, 1.0843, 1.0947, 1.0880, 1.0898, 1.0897, 1.0967, 1.0952,\n",
       "        1.0957, 1.0961, 1.0864, 1.0019], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_params.theta.data = my_samples[0][0]\n",
    "energy_fn( my_params() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "functional-mauritius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0974, 1.0969, 1.0944, 1.0948, 1.0971, 1.0918, 1.0967, 1.0985, 1.0947,\n",
       "        1.0888, 1.0954, 1.0707, 1.0810, 1.0850, 1.0779, 1.0712, 1.0941, 1.0977,\n",
       "        1.0838, 1.0955, 1.0984, 1.0900, 1.0967, 1.0668, 1.0951, 1.0948, 1.0972,\n",
       "        1.0951, 1.0694, 1.0748, 1.0976, 1.0936, 1.0956, 1.0977, 1.0979, 1.0908,\n",
       "        1.0893, 1.0956, 1.0883, 1.0946], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_params.theta.data = my_samples[-2][0]\n",
    "energy_fn( my_params() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
