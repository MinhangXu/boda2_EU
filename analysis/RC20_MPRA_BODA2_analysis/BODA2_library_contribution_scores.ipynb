{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sealed-reproduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "import shutil\n",
    "import random\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (random_split, DataLoader, TensorDataset, ConcatDataset)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "from Bio import motifs\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "import boda\n",
    "from boda.common import constants, utils\n",
    "\n",
    "boda_src = os.path.join( os.path.dirname( os.path.dirname( os.getcwd() ) ), 'src' )\n",
    "sys.path.insert(0, boda_src)\n",
    "\n",
    "from main import unpack_artifact, model_fn\n",
    "from pymeme import streme, parse_streme_output\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "from boda.generator.plot_tools import matrix_to_dms, ppm_to_IC, ppm_to_pwm, counts_to_ppm\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "normal-station",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from 20211113_021200 in eval mode\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "archive unpacked in ./\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('./artifacts'):\n",
    "    shutil.rmtree('./artifacts')\n",
    "hpo_rec = 'gs://syrgoth/aip_ui_test/model_artifacts__20211113_021200__287348.tar.gz'\n",
    "unpack_artifact(hpo_rec)\n",
    "\n",
    "model_dir = './artifacts'\n",
    "model = model_fn(model_dir)\n",
    "#model.cuda()\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "atmospheric-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mpra_predictor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 pred_idx=0,\n",
    "                 ini_in_len=200,\n",
    "                 model_in_len=600,\n",
    "                 cat_axis=-1):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.pred_idx = pred_idx\n",
    "        self.ini_in_len = ini_in_len \n",
    "        self.model_in_len = model_in_len\n",
    "        self.cat_axis = cat_axis       \n",
    "        \n",
    "        try: self.model.eval()\n",
    "        except: pass\n",
    "        \n",
    "        self.register_flanks()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pieces = [self.left_flank.repeat(x.shape[0], 1, 1), x, self.right_flank.repeat(x.shape[0], 1, 1)]\n",
    "        in_tensor = torch.cat( pieces, axis=self.cat_axis)\n",
    "        out_tensor = self.model(in_tensor)[:, self.pred_idx]\n",
    "        return out_tensor\n",
    "    \n",
    "    def register_flanks(self):\n",
    "        missing_len = self.model_in_len - self.ini_in_len\n",
    "        left_idx = - missing_len//2 + missing_len%2\n",
    "        right_idx = missing_len//2 + missing_len%2\n",
    "        left_flank = utils.dna2tensor(constants.MPRA_UPSTREAM[left_idx:]).unsqueeze(0)\n",
    "        right_flank = utils.dna2tensor(constants.MPRA_DOWNSTREAM[:right_idx]).unsqueeze(0)         \n",
    "        self.register_buffer('left_flank', left_flank)\n",
    "        self.register_buffer('right_flank', right_flank) \n",
    "\n",
    "def isg_contributions(sequences,\n",
    "                      predictor,\n",
    "                      num_steps=50,\n",
    "                      num_samples=20,\n",
    "                      eval_batch_size=1024,\n",
    "                      theta_factor=15,\n",
    "                      num_workers=0):\n",
    "    \n",
    "    batch_size = eval_batch_size // num_samples\n",
    "    temp_dataset = TensorDataset(sequences)\n",
    "    temp_dataloader = DataLoader(temp_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    all_salient_maps = []\n",
    "    all_gradients = []\n",
    "    for local_batch in tqdm(temp_dataloader):\n",
    "        target_thetas = (theta_factor * local_batch[0].cuda()).requires_grad_()\n",
    "        #base_thetas = theta_factor / 3 * torch.ones_like(target_thetas)\n",
    "        line_gradients = []\n",
    "        for i in range(0, num_steps + 1):\n",
    "            point_thetas = (i / num_steps * target_thetas)\n",
    "            #point_thetas = base_thetas + i / num_steps * (target_thetas - base_thetas)\n",
    "            point_distributions = F.softmax(point_thetas, dim=-2)\n",
    "\n",
    "            nucleotide_probs = Categorical(torch.transpose(point_distributions, -2, -1))\n",
    "            sampled_idxs = nucleotide_probs.sample((num_samples, ))\n",
    "            sampled_nucleotides_T = F.one_hot(sampled_idxs, num_classes=4)\n",
    "            sampled_nucleotides = torch.transpose(sampled_nucleotides_T, -2, -1)\n",
    "            distribution_repeater = point_distributions.repeat(num_samples, *[1 for i in range(3)])\n",
    "            sampled_nucleotides = sampled_nucleotides - distribution_repeater.detach() + distribution_repeater \n",
    "            samples = sampled_nucleotides.flatten(0,1)\n",
    "\n",
    "            preds = predictor(samples)\n",
    "            point_predictions = preds.unflatten(0, (num_samples, target_thetas.shape[0])).mean(dim=0)\n",
    "            point_gradients = torch.autograd.grad(point_predictions.sum(), inputs=point_thetas, retain_graph=True)[0]\n",
    "            line_gradients.append(point_gradients)\n",
    "            \n",
    "        gradients = torch.stack(line_gradients).mean(dim=0).detach()\n",
    "        all_salient_maps.append(gradients * target_thetas.detach())\n",
    "        all_gradients.append(gradients)\n",
    "    return torch.cat(all_salient_maps).cpu(), theta_factor * torch.cat(all_gradients).cpu()\n",
    "\n",
    "def df_to_onehot_tensor(in_df, seq_column='nt_sequence'):\n",
    "    onehot_sequences = torch.stack([utils.dna2tensor(subsequence) \\\n",
    "                                for subsequence in tqdm(in_df[seq_column])])\n",
    "    return onehot_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "international-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "boda2_df = pd.read_csv('BODA2_MPRA_results_pred_v3.txt', sep=' ', low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dutch-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop controls ands check lengths\n",
    "\n",
    "no_controls_df = boda2_df[boda2_df['method'].notnull()].copy().reset_index(drop=True)\n",
    "# no_controls_df['seq_len'] = no_controls_df.progress_apply(lambda x: len(x['sequence']), axis=1)\n",
    "\n",
    "# no_controls_df['seq_len'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "southeast-replacement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a617108807b4f60a7db8fe6236626e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get one-hot sequences\n",
    "\n",
    "sequences = no_controls_df['sequence'].tolist()\n",
    "onehot_sequences = torch.stack([utils.dna2tensor(sequence) for sequence in tqdm(sequences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "saving-relationship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d0c08368f340fe900bf0692fb1b5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e245a413254e95a040acbfdab5f579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d780ed5f6aaa41f481c86712fc1f454e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10h 3min 40s, sys: 42.6 s, total: 10h 4min 23s\n",
      "Wall time: 10h 4min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Compute contributions\n",
    "\n",
    "seq_len = 200\n",
    "eval_batch_size = 1040\n",
    "num_sequences = onehot_sequences.shape[0]\n",
    "\n",
    "predictors = [mpra_predictor(model=model, pred_idx=i, ini_in_len=seq_len).cuda() for i in range(3)]\n",
    "\n",
    "cell_idxs = {0: 'K562', 1: 'HepG2', 2:'SKNSH'}\n",
    "for idx, predictor in enumerate(predictors):\n",
    "    contributions, _ = isg_contributions(onehot_sequences, predictor, eval_batch_size=eval_batch_size)\n",
    "    contributions = contributions.sum(dim=1)\n",
    "    str_contribution_list = [np.array2string(contributions[i,...].numpy(), separator=' ', precision=16, max_line_width=1e6) \\\n",
    "                         for i in range(num_sequences)]\n",
    "    no_controls_df[f'contrib_{cell_idxs[idx]}'] = str_contribution_list\n",
    "    no_controls_df.to_csv('BODA2_MPRA_results_no_controls_pred_contributions.txt', index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "quarterly-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_controls_df.to_csv('BODA2_MPRA_results_no_controls_pred_contributions.txt', index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-singing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
